\documentclass{article}
\usepackage[latin1]{inputenc}
\usepackage{latexsym}
\usepackage[german]{babel}
\usepackage[a4paper]{geometry}
\geometry{textwidth=18cm, textheight=24cm} 
\parindent0em
\pagenumbering{arabic}
\begin{document}

\section*{Pastry}

\begin{itemize}

\item KnotenIDs zwischen 0 und $2^{128}-1$ (zufällig generiert)
\item Message wird an Knoten weitergeleitet, dessen KnotenID am dichtesten an Message-hash-value liegt
\item Jeder Knoten speichert Routing-tabel, Neighbourhood-set, Leaf-set
\item aufgrund einer Nachbarschaftsmetrik werden Nachrichten an den nahegelegensten Knoten unter denen aus den Tabellen in Frage kommenden Knoten gesendet

\end{itemize}

\section*{Scribe}
\begin{itemize}
\item scalable group communication-system (PubSub) built on top of Pastry
\item each group has a 160bit groupID
\item nodes which subscribe to a group, form a multicast-tree, nodeID of the root-node (Broker) is numerically closest to topicID 
\end{itemize}

\section*{FeedTree}
\begin{itemize}
\item a micronews distribution-system
\item uses p2p-overlay network to distribute RSS-feeds
\item peers in network share bandwith costs $\rightarrow$ reduces load on provider
\item distribution via Scribe
\end{itemize}

\section*{TMTP}
\begin{itemize}
\item Tree-based Multicast Transport Protocol
\item designed for efficient delivery of messages to nodes dynamically joining and leaving the network
\item group-leaders are organized in a hierarchical tree
\item group-members are as well organized in a hierarchical tree (subnet/domain)
\item Transmission rate controlled by sliding window based protocol
\item packets are sent only to direct children
\item children multicast NACK in combination with nack supression when missing packets are detected
\item parent sends packet again (multicast) with TTL
\item multicast sending and suppression of nacks reduces number of nacks
\item ACKs are sent directly and immediately to the parent after receiving packet
\item periodic positive ACKs ensure reliability of children
\item retransmission timers ensure receive of packets
\item two timers for retransmitting: $T_{retrans}$: after expiring packets will be resend; $T_{ack}$: after expiring ACK will be sent
\item this helps to reduce resending of packets if ACKs are lost

\end{itemize}

\section*{TCP}
van Jacobson stellt heraus, dass bei Stauaufkommen nur exponentielles Inkrementieren der Timer Erfolg verspricht, denn Netzwerke sind lineare
Systeme, d. h. sind sie stabil, so ist die Stabilität exponentiell.


\newpage
\section*{Algorithmus zur Koordination der Broker bezüglich des Pollings der Publisher}
Zunächst muss gesagt werden, dass es grundsätzlich nicht möglich ist, eine gleichzeitige Aktualisierung und Verbreitung der RSS-Feeds seitens der
Broker zum
Zeitpunkt der Aktualisierung seitens der Publisher zu erreichen, da zu keinem Zeitpunkt ermittelt werden kann, wann genau die nächste Aktualisierung
durch die Publisher erfolgen wird. Es kann nur versucht werden, sich diesem Verhalten anzunähern. Je kürzer das Poll-Intervall desto kleiner die maximale
Zeitspanne zwischen
Aktualisierung und nächstem Polling. Eine sehr kurze Zeitspanne zwischen zwei Polls würde aber ein hohes Netzaufkommen bedeuten
(erst recht bei voneinander unabhängigem Pollen der Broker), was nicht wünschenswert ist. Es sollte deshalb versucht werden,
das Polling der Broker aufeinander abzustimmen und ein angemessenes Poll-Intervall zu erreichen.
\subsection*{Beschreibung des Algorithmus}
{\bf Voraussetzung:} RSS-Feeds sollten das Tag ``lastBuildDate'' unterstützen und ein Tag, welches Auskunft über ein minimales Update-Intervall 
(z.B. ``minUpdateInterval'') liefert.
Das minimale Update-Intervall sagt aus, welche Zeitspanne mindestens vergehen muss, bevor eine neue Aktualisierung der Feeds erfolgt.\\

Bei diesem Algorithmus soll erreicht werden, dass verhältnismäßig möglichst
wenige Publisher eine gleichzeitige Aktualisierung der Feeds vornehmen. Die neuen Feeds werden dann den Brokern über das Netzwerk übersand.\\
Notwendig ist pro Publisher ein Poll-Timer, der bestimmt, wann das nächste Polling zu erfolgen hat. Ist dieser Timer abgelaufen, erfragt der Publisher beim
RSS-Server den aktuellen Feed. Ist dieser nicht neuer als der bisher beim Publisher vorhandene Feed, wird lediglich der Poll-Timer neu gesetzt (s.u.).
Ist der neue Feed hingegen aktueller, wird sowohl der Poll-Timer neu gesetzt als auch dieser neue Feed dem Nachbarbroker entsprechend den vorhandenen
Filterregeln übersand; jeder Nachbarbroker leitet seinerseits diesen neuen Feed an die jeweiligen Nachbarbroker weiter,
falls der Feed hier ebenfalls aktueller ist als der bisherige. Allerdings
wird der Poll-Timer nur in diesem Fall neu gesetzt. Das setzen des Poll-Timers geschieht folgendermaßen: Aus ``lastBuildDate'' und ``minUpdateInterval''
wird die ungefähre Zeitspanne ``nextAktualisation'' zur nächsten Aktualisierung durch den Publisher berechnet. Für den Wert des Poll-Timers $pt$ soll
nun gelten: $nextAktualisation \leq pt \leq 2*nextAktualisation$. $pt$ wird in diesem Bereich zufällig gewählt. Somit sollte es relativ wenige Publisher
geben, die gleichzeitig den aktuellen Stand beim RSS-Server erfragen. Nach erfolgreicher Aktualisierung wird mit hoher Wahrscheinlichkeit ein anderer
Publisher den Stand beim nächsten Mal erfragen. Außerdem ist gewährleistet, dass bei hoher Publisheranzahl der RSS-Server nach Ablauf der Poll-Timer
in regelmäßigen Abständen kontaktiert wird, falls zu diesem Zeitpunkt noch keine Aktualisierung vorlag.\\
Tritt ein neuer Knoten dem Netzwerk bei, so wird dieser den aktuellen Stand bei seinem nächsten Nachbarn erfragen.\\

Beobachtungen der Simulation:
\begin{itemize}
\item Anfrageverteilung und -intervall hängen von zwei Faktoren ab: Subscriber-TTL und Zufallsspanne
\item Um Skalierung des Netzes zu erreichen, müssen diese Parameter angepasst werden
\end{itemize}
Weitere Ideen:
\begin{itemize}
\item Zufallsspanne muss an Subscriberanzahl angepasst werden
\item Subscriber-TTL muss an tatsächliches momentanes Aktualisierungsintervall des RSS-Servers angepasst werden
\end{itemize}

Ermittlung der Subscriberanzahl:\\
Broker bestimmen die Netzgröße: Netzgröße bestimmt sich aus Summe aller Teilnetze plus Anzahl der eigenen Subscriber. Größe des Teilnetzes wird an
die entsprechenden Nachbarbroker übersendet: Gesamtgröße - Teilnetzgröße des Nachbarbrokers. In regelmäßigen Zeitabständen (Aktualisierungstimer -pro
Nachbarbroker) wird eine Aktualsisierung der
Teilnetzgröße an die Nachbarbroker übersand. Diese antworten mit einer Bestätigung. Wird nach einer gewissen Zeitspanne keine Bestätigung
(Bestätigungstimer) erhalten, gilt das Teilnetz als abgekoppelt. Ein Broker, der von einem Nachbarbroker ein Aktualisierung erhält, terminiert bestehende
Aktualisierungs- und Bestätigungstimer für diesen Nachbarbroker.

\subsection*{27.03.06}
Simulation: habe Simulation eines Uploads eingebaut: Broker warten, bis Feed beim Adressaten angekommen ist. Broker senden Feeds zuerst an Nachbarbroker, dann
an Subscriber.\\\\
Statistische Analyse: Rate der gesparten Anfragen und Rate der Netzfeeds:\\
gesparte Anfragen = Nazahl der Feeds, die ein Subscriber über das Netz erhält.\\
Rate der gesparten Anfragen = (100 * gesparte Anfragen) / ( erhaltene Anfragen + gesparte Anfragen )\\
Rate der Netzfeeds = ( 100 * Netzfeeds ) / ( Serverfeeds + Netzfeeds )\\

Idee zur Adaption der Publisher:\\\\
Ermittlung der Netzgröße könnte vermieden werden, wenn die Zufallsspanne durch die prozentuale Rate der Feeds, die über das Netzwerk kommen, und durch
die Aktualität der Feeds bestimmt wird. Dazu muss ein Mass für den Aktualitätsgrad bestimt werden. Eine geringe prozentuale Rate der Netzwerkfeeds erhöht die Zufallsspanne,
während eine geringe Aktualitätsrate die Zufallsspanne erniedrigt. Es gilt, eine Formel zu finden, welche beide Parameter vereinigt und das Optimum bestimmt.
Mit solch einer Lösung wäre es nicht mehr notwendig, das Netz auf eine Baumstruktur zu beschränken, sondern Zyklen könnten erlaubt werden.
\\\\
weitere Beobachtungen:\\
Bei niedriger serverseitigen Feed-Update-Rate und hoher Übermittlungsgeschwindigkeit liegt die (rel.) Rate der gesparten Nachrichten bei 90\% und die (rel.)
Rate der Netzfeeds bei 95\%.\\
Bei höherer Update-Rate und nidrieger Übermittlungsgeschwindigkeit liegen beide Werte immer noch bei 85\%. 

\subsection*{28.03.06}
Bestimmung des Zufallsintervalls:\\
Aktualitätsgrad hat Priorität gegenüber der Netzfeedrate. Solange sich der Aktualitätsgrad in akzeptablem Rahmen befindet, wird das
Zufallsintervall vergrößert (z.B. bis zu einem Maximalwert). Wird der Aktualitätsgrad zu gering, so wird eine Aktualitätsskala in Relation
zum Zufallsintervall berechnet; nun sollte ein Mittelwert auf der Aktualitätsskala angestrebt werden. 
Idee zu Bestimmung von TTL (falls nicht übermittelt) und Altualität der Feeds:\\
Bei Erhalt eines Feeds bestimmt sich der Aktualitätsgrad anhand des am zeitlich am weitesten zurückliegenden Eintrags. Liegt die Differenz des
jetzigen Zeitpunktes zu diesem Eintrag innerhalb des bisher berechneten TTL, so ist der Feed innerhalb des gewünschten Aktualitätsspektrums.
Ist es nicht der Fall, so ist der Aktualitätsgrad zu gering. Zunächst wird geprüft, ob der bisherige TTL noch aktuell ist.\\
TTL:\\  
Aktualisierungsrate auf Serverseite wird durch Mittelwert der Veröffentlichungszeitpunkte der einzelnen Einträge eines Feeds bestimmt. Stimmt
dieser mit bisherigem TTL nicht überein, wird dieser angepasst; darauf hin erfolgt eine Anpassung des Zufallsintervalls.\\
Zufallsintervall:\\
- wird verringert bei zu niedrigem Aktualitätsgrad.

\subsection*{29.03.06}
Einstieg in Python: Script zum update von RSS-Feeds geschrieben

\subsection*{30.03.06}
Aus der Stochastik:\\\\
Berechnung des TTLs über Bestimmung des Mittelwerts der zeitlichen Ereignisse der einzelnen Events eines bzw. der letzten Feeds. Dies entspricht
dem Erwartungswert. ... (noch   --  Standardabweichung ansehen!)\\\\
Illustration des Zusammenhanges zwischenTTL, Zufallsintervall und Aktualitätsgrad:\\
Ein Maß für den Aktualitätsgrad könnte die Anzahl neuer Events innnerhalb eines Feeds sein. Je mehr neue Events vorhanden sind desto geringer
ist der Aktualitätsgrad. Bei Erhalt eines Feeds wird der Mittelwert der zeitlichen Differenzen der einzelnen neuen Events und einer festen Anzahl
alter Events berechnet. Ist der Aktualitätsgrad zu gering und ist der Mittelwert kleiner als der TTL, so muss dieser neu gesetzt
werden und dass Polling-Verhalten darauf abgestimmt werden. Stimmen beide jedoch überein, so muss das Zufallsintervall angepasst werden, da
dieses zu groß ist.

\subsection*{31.03.06}
Habe Deadlock auslösenden Bug im file PubSub.java gefunden: FeedRequestTask
hat eigenmächtig FeedRequest an Server geschickt(schlecht!) und dabei auf
synchronized Methode feedRequest() von PubSubNode zugegriffen, hat also ein
Lock auf PubSubNode erhalten. Run() der Klasse
Engine ist ebenfalls synchronized und der FeedRequest muss auf das Lock warten. Ruft run() nun receiveMessage auf, komt es zum Deadlock bei der Methode
isBlocked() in PubSubNode, da diese ebenfalls das Lock benötigt, welches
FeedRequestTask bereits besitzt.\\
Umgehung: FeedRequestTask sendet Benachrichtigung (RequestFeedMessage) an
PubSubNode, fordert somit kein Lock auf PubSubNode an.

\subsection*{2.4.06}
Neuer Ansatz zur Bestimmung des Aktualitätsgrades bzw. Verzögerungsgrades von Feeds:\\
Jeder User kann einen Aktualitätsrahmen festlegen: dieser sagt aus, nach
welcher Zeit er spätestens über ein neues Event informiert werden soll.\\
\\

Aktualitätsgrad = Refreshrate*100/Laufzeit\\
Verzögerungsgrad = Zeitdifferenz*100 / Refreshrate\\
\\
Zeitdifferenz ist: aktuelle Zeit - PubDate des am längesten zurückliegenden Events

\subsection*{5.4.06}
Anzeige von average uptodate-ratio, delayed-messages und average message-delay im Statistikfenster

\subsection*{6.4.06}
Implementierung von Subscribern, die nach einem Refresh-Intervall den Feed
beim Server erfragen.

\subsection*{13.04.06}
Simulator: Subscriber registrieren sich bei ihren Brokern in regelmässigen
Intervallen.  Unterbleibt Registrierung aufgrund von Blockierung, so
betrachtet der Broker den entsprechenden Subscriber nach einem Timeout als
abgemeldet.\\
Bug: zeitweise kommt es zu NullPointerExceptions in Message.drawObj(), da src==null
gilt. Es hat sich gezeigt, dass bereits in
PubSub.AckTimerMessage.getBroker()==null gilt. Dieser Fehler ist mir
unerklärlich und eigentlich unmöglich, da jeder AckTimerTask mit broker!=null
initialisiert wird (wurde durch Wertecheck überprüft). Fehler wurde gekapselt
und stört nun nicht mehr den Simulationsprozess.

\subsection*{14.04.06}
Neue Klasse: QueueingRSSServer\\
Dieser Server unterhält eine Queue fester Größe, in der neue FeedRequests
eingereiht werden. Überzählige Feeds werden abgewiesen
bzw. verworfen. Simulation der Belastung des Servers durch Bearbeitung eines
Feeds erfolgt durch abwarten einer Wartezeit, die der Übermittlungszeit eines
Feeds entspricht. Zusätzlich erfordern verworfene Requests eine gewisse
Bearbeitungszeit, so dass ein Ansturm von Requests den Server überlasten
können. Es zeigt sich, dass zu Beginn einer Session der Server zunächst
aufgrund der Fülle an Requests stark überlastet ist und nur eine sehr geringe
Antwortzeit erreicht wird.

\subsection*{16.04.06}
Habe vermutlich den Fehler der falschen Brokerreferenz gefunden:\\
Problem liegt im Konstruktoraufruf Message(): bereits im Konstruktor wird die
Message in die Messageliste eingetragen. Von Message abgeleitete Klassen
müssen zunächst den Superkonstruktor aufrufen und können erst anschliessend
spezielle Attribute setzen. Wird eine Message von einem separaten Task
erzeugt, so kann es vorkommen, dass nach Superkonstruktoraufruf und vor dem
initialisieren
der speziellen Attribute die Message verarbeitet wird. Dann wären die
speziellen Parameter noch nicht gesetzt.\\
Abhilfe: zusätzliche Methode send() in der Klasse Message: erst der Aufruf von
send() trägt die Message in die zu verarbeitende Nachrichtenliste ein. Dafür
muss dann also für jede neu erzeugt Nachricht die Operation send() aufgerufen
werden (am besten direkt nach Konstruktoraufruf).\\\\

Klientseitiges messen der Serverauslastung:\\
Idee: Staukontrolle in Anlehnung an Congestion-Control bei TCP. Problem:
Es kann nicht festgestellt werden, auf welche Anfrage sich eine Antwort vom
Server bezieht.\\\\

Literatur:
\begin{itemize}
  \item van Jacobson, Congestion avoidance and control
  \item Zhang, L. Why TCP timers don't work well
\end{itemize}

für Congestion-Control:\\
Sum[i=1;n](a*i)=(n*(a*n+a))/2\\
Für den neuen Timeoutwert ergibt sich (wir müssen durch n teilen);\\
(a*n+a)/2

\subsection*{18.04.2006}
Staukontrolle implementiert.

\subsection*{19. - 25.04.2006}
Generische Konstruktion der Simulation: Klassen der PubSubs, RSSServer und
Broker können im eigenen Konfigurationsfile definiert werden. Somit lassen sich
beliebige Kombinationen bzw. Szenarien leicht erstellen.
Infofenster für PubSub und RSSServer implementiert. Individuelle Parameter
lassen sich anpassen. Nützlicher grafischer Schnickschnack wie
Verbindungslinie zu Bezugsknoten. Bin dabei auf einen eingeschlichenen Fehler
gestossen: beim Hinzufügen der updateRefreshTimer-Methoden wurde nun auch ein
Refreshing bei einer alten von einem Broker erhaltenen Nachricht
durchgeführt. Habe es glücklicherweise durch Zufall entdeckt, da sich
dieser Fehler nicht markant äusserte.

\subsection*{28.04.2006}
Idee für evtl. Verbesserung der Anpassung der Pollingrate:\\
Problem: Subscriber, deren Anfragen vom Server immer wieder verworfen werden,
steigern ihren RTO endlos. Damit sinkt für nachfolgende Anfragen stetig die
Chance, in die Serverqueue aufgenommen zu werden.\\
Workaround: Jeder Subscriber übermittelt in der von ihm ausgesandten
RSSFeed-Nachricht den vom ihm  ermittelten RTT. Erhält ein Subscriber solch
eine Nachricht durch einen Broker, so betimmt sich sein neuer RTT aus dem
Maximum seines alten und des übermittelten Wertes.\\\\
Habe neue Funktionalität eingebaut, Ergebnis ist aber bei schlechter
Antwortzeit durch den Server nicht zufrieden stellend: Der RTT zirkuliert
meistens um relativ kleine Werte, Zahl der abgewiesenen Nachrichten steigt
an.\\
Neue Idee: neuer RTT bestimmt sich als Mittelwert zwischen altem und
übermitteltem Wert. Sollte dazu führen, dass Subscriber, deren Anfragen
wiederholt verworfen werden, ihren RTT erniedrigen können. Sehr niedrige RTT
aufgrund schneller Serverantwort im Ausnahmefall wirkt sich damit ebenfalls
nicht sehr störend auf das Gesamtverhalten aus.\\\\
Resultat sieht sehr gut aus!\\\\
Kam auf die Idee, nach der Anpassung ein resetRequestFeedTimerCounter()
auszuführen aufgrund der Tatsache, dass ja nun ein anderer RTT als
Berechnungsgrundlage für die mittlere Serverantwort dient. Das Ergebnis in der
Simulation war jedoch fatal! Es fand kaum noch eine Steigerung des RTO's
statt, die Serrverqueue war ständig stark überlaufen. Ist auch verständlich,
da nun jede Serverantwort als direkte Antwort auf die erste Anfrage
interpretiert wird, somit kann kaum eine Steigerung des RTO stattfinden. Was
mich jedoch stutzig gemacht hat in der Logik ohne
resetRequestFeedTimerCounter() ist gerade die Tatsache, dass ja nun als
Berechnungsgrundlage für die Serverantwort der neue RTT dient, wodurch doch
eigentlich das Ergebnis verfälscht wird, da der Subscriber in Wirklichkeit
nicht diesen Betrag an Zeit gewartet hat. Aber angenommen, wir hätten nur den
ursprünglichen RTT als Grundlage genommen, hätte sich am RTO letztendlich
nichts geändert, wir würden als Ergebnis immer die entsprechend hohe Summe
erhalten! Das Problem sind ja gerade verloren gegangene Anfragen. Dieses
Problem soll ja nun durch die neue RTT-Bestimmung umgangen werden. Also macht
der neue RTT als Grundlage für die Berechnung Sinn!\\
Innerhalb der methode updateRequestTimerByOldFeedFromBroker() muss nun
grundsätzlich ein updateRequestTimer(long) erfolgen, damit sichergestellt ist,
dass die Timerperiode auf den neuen RTT gesetzt wird. Als Timerdelay wird nun
das Minimum von neuem RTO (interval) und planmässiger Zeitdifferenz bis zum
nächsten Timeout genommen. Dies gewährleistet, dass es immer zu einem Timeout
kommt, auch wenn der neue RTO größer ist als die Zeit bis zum nächsten Timeout.

\subsection*{14.09.2006}
Beobachtungen und Kommentare zu durchgeführten Experimenten:

\begin{itemize}
\item NoBalancing: die auftretenden Spitzen verteilen sich exponentiell über den zeitl. Verlauf. Mögl.Erklärung: zuerst ankommende Anfragen
``sperren'' die restlichen aus. Die auftretenden Spitzen kommen durch Anfragen der restlichen Klienten, die nun keine Chance haben, in die
Queue zu gelangen.
\end{itemize}


\end{document}
