\documentclass{article}
\usepackage[latin1]{inputenc}
\usepackage{latexsym}
\usepackage[german]{babel}
\usepackage[a4paper]{geometry}
\geometry{textwidth=18cm, textheight=24cm} 
\parindent0em
\pagenumbering{arabic}
\begin{document}

\section*{Pastry}

\begin{itemize}

\item KnotenIDs zwischen 0 und $2^{128}-1$ (zufällig generiert)
\item Message wird an Knoten weitergeleitet, dessen KnotenID am dichtesten an Message-hash-value liegt
\item Jeder Knoten speichert Routing-tabel, Neighbourhood-set, Leaf-set
\item aufgrund einer Nachbarschaftsmetrik werden Nachrichten an den nahegelegensten Knoten unter denen aus den Tabellen in Frage kommenden Knoten gesendet

\end{itemize}

\section*{Scribe}
\begin{itemize}
\item scalable group communication-system (PubSub) built on top of Pastry
\item each group has a 160bit groupID
\item nodes which subscribe to a group, form a multicast-tree, nodeID of the root-node (Broker) is numerically closest to topicID 
\end{itemize}

\section*{FeedTree}
\begin{itemize}
\item a micronews distribution-system
\item uses p2p-overlay network to distribute RSS-feeds
\item peers in network share bandwith costs $\rightarrow$ reduces load on provider
\item distribution via Scribe
\end{itemize}

\section*{TMTP}
\begin{itemize}
\item Tree-based Multicast Transport Protocol
\item designed for efficient delivery of messages to nodes dynamically joining and leaving the network
\item group-leaders are organized in a hierarchical tree
\item group-members are as well organized in a hierarchical tree (subnet/domain)
\item Transmission rate controlled by sliding window based protocol
\item packets are sent only to direct children
\item children multicast NACK in combination with nack supression when missing packets are detected
\item parent sends packet again (multicast) with TTL
\item multicast sending and suppression of nacks reduces number of nacks
\item ACKs are sent directly and immediately to the parent after receiving packet
\item periodic positive ACKs ensure reliability of children
\item retransmission timers ensure receive of packets
\item two timers for retransmitting: $T_{retrans}$: after expiring packets will be resend; $T_{ack}$: after expiring ACK will be sent
\item this helps to reduce resending of packets if ACKs are lost

\end{itemize}
\newpage
\section*{Algorithmus zur Koordination der Broker bezüglich des Pollings der Publisher}
Zunächst muss gesagt werden, dass es grundsätzlich nicht möglich ist, eine gleichzeitige Aktualisierung und Verbreitung der RSS-Feeds seitens der
Broker zum
Zeitpunkt der Aktualisierung seitens der Publisher zu erreichen, da zu keinem Zeitpunkt ermittelt werden kann, wann genau die nächste Aktualisierung
durch die Publisher erfolgen wird. Es kann nur versucht werden, sich diesem Verhalten anzunähern. Je kürzer das Poll-Intervall desto kleiner die maximale
Zeitspanne zwischen
Aktualisierung und nächstem Polling. Eine sehr kurze Zeitspanne zwischen zwei Polls würde aber ein hohes Netzaufkommen bedeuten
(erst recht bei voneinander unabhängigem Pollen der Broker), was nicht wünschenswert ist. Es sollte deshalb versucht werden,
das Polling der Broker aufeinander abzustimmen und ein angemessenes Poll-Intervall zu erreichen.
\subsection*{Beschreibung des Algorithmus}
{\bf Voraussetzung:} RSS-Feeds sollten das Tag ``lastBuildDate'' unterstützen und ein Tag, welches Auskunft über ein minimales Update-Intervall 
(z.B. ``minUpdateInterval'') liefert.
Das minimale Update-Intervall sagt aus, welche Zeitspanne mindestens vergehen muss, bevor eine neue Aktualisierung der Feeds erfolgt.\\

Bei diesem Algorithmus soll erreicht werden, dass verhältnismäßig möglichst
wenige Publisher eine gleichzeitige Aktualisierung der Feeds vornehmen. Die neuen Feeds werden dann den Brokern über das Netzwerk übersand.\\
Notwendig ist pro Publisher ein Poll-Timer, der bestimmt, wann das nächste Polling zu erfolgen hat. Ist dieser Timer abgelaufen, erfragt der Publisher beim
RSS-Server den aktuellen Feed. Ist dieser nicht neuer als der bisher beim Publisher vorhandene Feed, wird lediglich der Poll-Timer neu gesetzt (s.u.).
Ist der neue Feed hingegen aktueller, wird sowohl der Poll-Timer neu gesetzt als auch dieser neue Feed dem Nachbarbroker entsprechend den vorhandenen
Filterregeln übersand; jeder Nachbarbroker leitet seinerseits diesen neuen Feed an die jeweiligen Nachbarbroker weiter,
falls der Feed hier ebenfalls aktueller ist als der bisherige. Allerdings
wird der Poll-Timer nur in diesem Fall neu gesetzt. Das setzen des Poll-Timers geschieht folgendermaßen: Aus ``lastBuildDate'' und ``minUpdateInterval''
wird die ungefähre Zeitspanne ``nextAktualisation'' zur nächsten Aktualisierung durch den Publisher berechnet. Für den Wert des Poll-Timers $pt$ soll
nun gelten: $nextAktualisation \leq pt \leq 2*nextAktualisation$. $pt$ wird in diesem Bereich zufällig gewählt. Somit sollte es relativ wenige Publisher
geben, die gleichzeitig den aktuellen Stand beim RSS-Server erfragen. Nach erfolgreicher Aktualisierung wird mit hoher Wahrscheinlichkeit ein anderer
Publisher den Stand beim nächsten Mal erfragen. Außerdem ist gewährleistet, dass bei hoher Publisheranzahl der RSS-Server nach Ablauf der Poll-Timer
in regelmäßigen Abständen kontaktiert wird, falls zu diesem Zeitpunkt noch keine Aktualisierung vorlag.\\
Tritt ein neuer Knoten dem Netzwerk bei, so wird dieser den aktuellen Stand bei seinem nächsten Nachbarn erfragen.\\

Beobachtungen der Simulation:
\begin{itemize}
\item Anfrageverteilung und -intervall hängen von zwei Faktoren ab: Subscriber-TTL und Zufallsspanne
\item Um Skalierung des Netzes zu erreichen, müssen diese Parameter angepasst werden
\end{itemize}
Weitere Ideen:
\begin{itemize}
\item Zufallsspanne muss an Subscriberanzahl angepasst werden
\item Subscriber-TTL muss an tatsächliches momentanes Aktualisierungsintervall des RSS-Servers angepasst werden
\end{itemize}

Ermittlung der Subscriberanzahl:\\
Broker bestimmen die Netzgröße: Netzgröße bestimmt sich aus Summe aller Teilnetze plus Anzahl der eigenen Subscriber. Größe des Teilnetzes wird an
die entsprechenden Nachbarbroker übersendet: Gesamtgröße - Teilnetzgröße des Nachbarbrokers. In regelmäßigen Zeitabständen (Aktualisierungstimer -pro
Nachbarbroker) wird eine Aktualsisierung der
Teilnetzgröße an die Nachbarbroker übersand. Diese antworten mit einer Bestätigung. Wird nach einer gewissen Zeitspanne keine Bestätigung
(Bestätigungstimer) erhalten, gilt das Teilnetz als abgekoppelt. Ein Broker, der von einem Nachbarbroker ein Aktualisierung erhält, terminiert bestehende
Aktualisierungs- und Bestätigungstimer für diesen Nachbarbroker.

\subsection*{27.03.06}
Simulation: habe Simulation eines Uploads eingebaut: Broker warten, bis Feed beim Adressaten angekommen ist. Broker senden Feeds zuerst an Nachbarbroker, dann
an Subscriber.\\\\
Statistische Analyse: Rate der gesparten Anfragen und Rate der Netzfeeds:\\
gesparte Anfragen = Nazahl der Feeds, die ein Subscriber über das Netz erhält.\\
Rate der gesparten Anfragen = (100 * gesparte Anfragen) / ( erhaltene Anfragen + gesparte Anfragen )\\
Rate der Netzfeeds = ( 100 * Netzfeeds ) / ( Serverfeeds + Netzfeeds )\\

Idee zur Adaption der Publisher:\\\\
Ermittlung der Netzgröße könnte vermieden werden, wenn die Zufallsspanne durch die prozentuale Rate der Feeds, die über das Netzwerk kommen, und durch
die Aktualität der Feeds bestimmt wird. Dazu muss ein Mass für den Aktualitätsgrad bestimt werden. Eine geringe prozentuale Rate der Netzwerkfeeds erhöht die Zufallsspanne,
während eine geringe Aktualitätsrate die Zufallsspanne erniedrigt. Es gilt, eine Formel zu finden, welche beide Parameter vereinigt und das Optimum bestimmt.
Mit solch einer Lösung wäre es nicht mehr notwendig, das Netz auf eine Baumstruktur zu beschränken, sondern Zyklen könnten erlaubt werden.
\\\\
weitere Beobachtungen:\\
Bei niedriger serverseitigen Feed-Update-Rate und hoher Übermittlungsgeschwindigkeit liegt die (rel.) Rate der gesparten Nachrichten bei 90\% und die (rel.)
Rate der Netzfeeds bei 95\%.\\
Bei höherer Update-Rate und nidrieger Übermittlungsgeschwindigkeit liegen beide Werte immer noch bei 85\%. 

\subsection*{28.03.06}
Bestimmung des Zufallsintervalls:\\
Aktualitätsgrad hat Priorität gegenüber der Netzfeedrate. Solange sich der Aktualitätsgrad in akzeptablem Rahmen befindet, wird das
Zufallsintervall vergrößert (z.B. bis zu einem Maximalwert). Wird der Aktualitätsgrad zu gering, so wird eine Aktualitätsskala in Relation
zum Zufallsintervall berechnet; nun sollte ein Mittelwert auf der Aktualitätsskala angestrebt werden. 
Idee zu Bestimmung von TTL (falls nicht übermittelt) und Altualität der Feeds:\\
Bei Erhalt eines Feeds bestimmt sich der Aktualitätsgrad anhand des am zeitlich am weitesten zurückliegenden Eintrags. Liegt die Differenz des
jetzigen Zeitpunktes zu diesem Eintrag innerhalb des bisher berechneten TTL, so ist der Feed innerhalb des gewünschten Aktualitätsspektrums.
Ist es nicht der Fall, so ist der Aktualitätsgrad zu gering. Zunächst wird geprüft, ob der bisherige TTL noch aktuell ist.\\
TTL:\\  
Aktualisierungsrate auf Serverseite wird durch Mittelwert der Veröffentlichungszeitpunkte der einzelnen Einträge eines Feeds bestimmt. Stimmt
dieser mit bisherigem TTL nicht überein, wird dieser angepasst; darauf hin erfolgt eine Anpassung des Zufallsintervalls.\\
Zufallsintervall:\\
- wird verringert bei zu niedrigem Aktualitätsgrad.

\subsection*{29.03.06}
Einstieg in Python: Script zum update von RSS-Feeds geschrieben

\subsection*{30.03.06}
Aus der Stochastik:\\\\
Berechnung des TTLs über Bestimmung des Mittelwerts der zeitlichen Ereignisse der einzelnen Events eines bzw. der letzten Feeds. Dies entspricht
dem Erwartungswert. ... (noch   --  Standardabweichung ansehen!)\\\\
Illustration des Zusammenhanges zwischenTTL, Zufallsintervall und Aktualitätsgrad:\\
Ein Maß für den Aktualitätsgrad könnte die Anzahl neuer Events innnerhalb eines Feeds sein. Je mehr neue Events vorhanden sind desto geringer
ist der Aktualitätsgrad. Bei Erhalt eines Feeds wird der Mittelwert der zeitlichen Differenzen der einzelnen neuen Events und einer festen Anzahl
alter Events berechnet. Ist der Aktualitätsgrad zu gering und ist der Mittelwert kleiner als der TTL, so muss dieser neu gesetzt
werden und dass Polling-Verhalten darauf abgestimmt werden. Stimmen beide jedoch überein, so muss das Zufallsintervall angepasst werden, da
dieses zu groß ist.

\subsection*{31.03.06}
Habe Deadlock auslösenden Bug im file PubSub.java gefunden: FeedRequestTask
hat eigenmächtig FeedRequest an Server geschickt(schlecht!) und dabei auf
synchronized Methode feedRequest() von PubSubNode zugegriffen, hat also ein
Lock auf PubSubNode erhalten. Run() der Klasse
Engine ist ebenfalls synchronized und der FeedRequest muss auf das Lock warten. Ruft run() nun receiveMessage auf, komt es zum Deadlock bei der Methode
isBlocked() in PubSubNode, da diese ebenfalls das Lock benötigt, welches
FeedRequestTask bereits besitzt.\\
Umgehung: FeedRequestTask sendet Benachrichtigung (RequestFeedMessage) an
PubSubNode, fordert somit kein Lock auf PubSubNode an.


\end{document}
