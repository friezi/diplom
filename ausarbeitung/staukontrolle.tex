\subsection{Staukontrolle}
Seitdem Computer-Netzwerke explosionsartig an Größe und Komplexität zugenommen haben, hat sich ein Problem verstärkt bemerkbar gemacht: Datenstau.
Van Jacobson et. al. \cite{jacobson88congestion} schildern die Beobachtung, dass Mitte der 1980er Jahre Internet-Gateways 10\% der
ankommenden Pakete aufgrund von Pufferüberläufen verwarfen. Laut seiner Aussage lag dabei das Problem nicht in den Protokollspezifikationen selbst, sondern
hauptsächlich in deren Implementierungen. TCP (Transmission Control Protocol) ist ein verbindungsorientiertes Transportprotokoll, mit dessen Hilfe der Großteil
des Netzwerkverkehrs vonstatten geht. Im Laufe der Zeit wurden in TCP Mechanismen eingebaut und verbessert, um Datenstau festzustellen und soweit wie möglich
zu vermeiden.\\
\todo{Überleitung}
Auf dem Gebiet der Regelungstechnik beschäftigt man sich damit, wie eine Größe einen bestimmten vorgegebenen Wert erreichen und halten kann. Bei einer Regelung
finden Kontrollmechanismen
Anwendung, um Wertabweichungen festzustellen und auszugleichen.\\

Im Folgenden werden wir Techniken zur Adaption von Werten aus diesen Teilgebieten betrachten und diese auf ihre Tauglichkeit bezüglich der Lösung unseres
beschriebenen Problems untersuchen.
Nicht alle der vorgestellten Techniken sind ohne weiteres auf unsere Problemstellung anwendbar, und wir werden eine Lösung entwickeln, die auf die konkrete
Problemstellung unter Berücksichtigung der gegebenen Umstände zurecht geschnitten ist.

\subsubsection{Staukontrolle bei TCP}
\label{css:tcp}
TCP (Transmission Control Protocol) ist ein verbindungsorientiertes Über\-tra\-gungs\-pro\-to\-koll. Es kontrolliert die Datenübertragung zwischen Sender und
Empfänger der Endknoten. Dabei wird gewährleistet, dass jedes der einzelnen Datenpakete (die einen Datenstrom formen) den Empfänger erreicht
und dass die Ordnung der Pakete
innerhalb des Datenstroms bestehen bleibt. Bei Datenstau handelt es sich um Verlust von Datenpaketen. Falls es zu Datenstau kommt, so tritt dieser immer an
Verbindungsknoten (einschließlich des Empfangsknotens) auf und kann durch verschiedene Ursachen auf dem Weg zwischen Sender und Empfänger hervorgerufen werden:
\begin{description}
  \item [Bandbreiten:]
    Unterschiedliche Bandbreiten auf dem Weg zwischen Sender und Empfänger beeinflussen die Übertragungsgeschwindigkeit einer Verbindung
    nachteilig in der
    Form, dass die ``langsamste'' Leitung (also die mit der geringsten Bandbreite) die
    Gesamt-Übertragungsgeschwindigkeit vorgibt. Trifft eine schnelle Leitung auf eine langsame Leitung, so können die an der langsamen Leitung ankommenden
    Pakete nicht schnell genug weitergeleitet werden. An diesem Knoten kommt es zum Pufferüberlauf, Datenpakete gehen verloren.
  \item [Anzahl der Verbindungen:]
    An einem Knotenpunkt können mehrere Verbindungen zusammen kommen, die den Gesamt-Datenfluss an diesem Punkt erhöhen. Auch hier kann es zum Pufferüberlauf
    kommen, so dass Datenpakete verloren gehen.
\end{description}
Damit jedes ausgesandte Paket den Empfänger erreicht, werden in TCP Bestätigungs-Nachrichten (Acknowledgements, im Folgenden kurz $acks$ genannt) versandt.
Erhält der Sender für ein gesendetes TCP-Datenpaket kein $ack$, so wird er das Datenpaket erneut senden. Ein wichtiger Bestandteil eines Datenpaketes ist
die Sequenznummer \cite{RFC2581}. Anhand der Sequenznummer kann ein $ack$ eindeutig einem versendeten Datenpaket zugeordnet werden. Innerhalb des $acks$ vermerkt
der Empfänger ebenfalls, welches Datenpaket er als nächstes erwartet \cite{RFC793}.
Um eine Staukontrolle zu erreichen wurden einige Algorithmen in TCP integriert (siehe \cite{jacobson88congestion}, wir halten uns dabei an die englischen
Bezeichnungen):
\begin{itemize}
  \item slow-start
  \item round-trip-time variance estimation
  \item exponential retransmit timer backoff
  \item more aggressive receiver ack policy
  \item dynamic window sizing on congestion
  \item Karn's clamped retransmit backoff
  \item fast retransmit
\end{itemize}

Dabei soll erreicht werden, dass die maximal mögliche Bandbreite (begrenzt durch die minimale Bandbreite (``bottleneck'') auf dem Verbindungsweg, s. o.) voll
ausgenutzt wird, ohne
dass Pakete verloren gehen; es darf also kein Paket in das Netzwerk eingespeist werden, bevor ein altes Paket entfernt wurde (die Verbindung befindet sich dann im
``Equilibrium'', der Paketfluss ist ``conservative'' \cite{jacobson88congestion}). Im Folgenden wollen wir die wichtigsten der oben genannten Algorithmen
vorstellen. Eine genaue Herleitung und Analyse der Algorithmen geht jedoch über den Rahmen dieser Arbeit hinaus.
Wir verweisen auf die entsprechenden Quellen in den Literaturangaben.

\paragraph{more aggressive receiver ack policy:}
\footnote{Hier ist in \cite{jacobson88congestion} nicht eindeutig feststellbar,  worauf sich van Jacobson genau bezieht, da er diese Bezeichnung im weiteren Text
nicht mehr verwendet. Es erschien sinnvoll, die folgende im o. g. Text zu findende Erklärung diesem Thema zuzuordnen.}TCP
ist ``self-clocking'': da $acks$ erst nach Erhalt der entsprechenden Datenpakete versendet werden können, bestimmt die Rate der ankommenden $acks$ die
Rate, mit der weitere Datenpakete ausgesendet werden sollen. Die Senderate passt sich somit automatisch der Bandbreite an.

\paragraph{slow-start:}
Durch das ``self-clocking'' tritt nur beim Start des Datentransfers ein Problem auf, da
hier zunächst eine feste Rate gewählt werden muss. Diese wird zu Beginn relativ niedrig gewählt, bzw. ein Staufenster ``congestion window'' ($cngw$) 
bestimmt die Anzahl der Pakete pro Sendevorgang. Bei Start des Transfers oder nach Paketverlust wird die Größe des Staufenster auf 1 gesetzt.
Für jedes $ack$ wird das Staufenster um den Betrag 1 erhöht. Begrenzt wird dessen Größe durch das ``advertised receiver window'',
welches vom Empfänger festgelegt wird und angibt, wieviele Bytes maximal als nächstes übersendet werden sollen. Die Zunahme der Größe $w$ des
Staufensters geschieht in der Zeit
$rtt\cdot log_2w$, wobei $rtt$ die ``round-trip-time'' des letzten versendeten Datenpaketes ist (Zeit zwischen Versenden eines Datenpaketes und Erhalt des
entsprechenden $acks$). Siehe dazu \cite{jacobson88congestion,RFC2581}. 

\paragraph{round-trip-time variance estimation:}
\label{cssp:tcp_rtt}
$Acks$ können die Geschwindigkeit des Datenflusses steuern, doch was geschieht, wenn $acks$ aufgrund verloren gegangener Pakete ausbleiben? Müssen sich
beispielsweise bei voll ausgenutzter Bandbreite plötzlich zwei Datenströme dieselbe Leitung teilen, kommt es bei gleichbleibender Datentransferrate mit Sicherheit zu
Paketverlusten und somit zu
ausbleibenden $acks$. Der Sender muss einen Timer unterhalten, bei dessen Ablauf das zuletzt gesendete Datenpaket erneut versendet wird (im Folgenden als
``Wiederholung'' bezeichnet). Paketverlust kann auch
durch Beschädigung der Daten während der Übermittlung auftreten. Nach van Jacobson \cite{jacobson88congestion} liegt die Wahrscheinlichkeit dafür aber weit
unter 1\%. Daher lassen Timeouts bei gut eingestellten Timern mit sicherer Gewissheit auf Paketverluste schließen \footnote{Zur Problematik
bei Timern siehe \ref{css:timer}}. Diese Timeouts werden pro Verbindung dynamisch berechnet; im Folgenden bezeichnet $rto$ das ``retransmission timeout''-Intervall,
also die Zeitdifferenz bis zum nächsten Aussenden eines Datenpaketes. Entsprechend der TCP-Spezifikation
berechnet sich dieser Wert wie folgt \cite{18216}:
\begin{equation}
  rto=min\{UBound, max\{LBound, \beta \cdot srtt\}\}
\end{equation}
$\beta$ ist dabei ein empirisch ermittelter Varianz-Faktor, $UBound$ und $LBound$ sind untere und
obere Schranke für den $rto$, $srtt$ ist die ``smoothed roundtrip time'' und
wird wie folgt ermittelt:
\begin{equation}
  srtt= \alpha \cdot  srtt+ (1 - \alpha) \cdot  rtt
\end{equation} 
$\alpha$ ist ein ebenfalls empirisch ermittelter Glättungsfaktor (``smoothing factor''). Empfohlene Werte sind für $\alpha:$ $0.8 \sim 0.9$ und für $\beta:$
$1.3 \sim 2$ \cite{18216}.\\
Laut van Jacobson \cite{jacobson88congestion} liegt hierin folgende Problematik: $\beta$ kann sich höchstens an eine bis zu 30\% gesteigerte Last anpassen. Aber die
Varianz des Wertes $rtt$ steigert sich rapide mit ansteigender Last. Bei
Laststeigerung über die 30\%-Marke hinaus kommt es zu verspäteten $acks$. Der jeweilige abgelaufene Timer bewirkt eine Wiederholung des entsprechenden
Datenpaketes, was zu unnötiger Mehrarbeit des Netzwerkes und zu Bandbreitenverschwendung führt. Daher wird $\beta$ ebenfalls dynamisch berechnet.
Eine Berechnungsmethode findet sich in \cite{jacobson88congestion}.

\paragraph{exponential retransmit timer backoff:}
Um den Datenstau durch mehrfach ausgesandte Pakete nicht noch zu vermehren, muss sich der $rto$ stetig vergrößern.
Van Jacobson \cite{jacobson88congestion} stellt heraus, dass nur exponentielles Wachstum des $rto$ Erfolg verspricht.
Daher wird nach jedem erneuten Aussenden eines nicht bestätigten Datenpaketes der $rto$ verdoppelt.

\paragraph{dynamic window sizing on congestion:}
Ein Vergrößern des $rto$ verhindert nur einen zusätzlichen Datenstau durch erneut ausgesandte Datenpakete. Damit auch die im Anschluss daran neu
ausgesandten Pakete nicht wieder zum Anstieg des Datenstaus führen, wird ebenfalls die Größe der Staufenster $cwnd$ halbiert (exponentielle Abnahme).
Ausbleibende oder verzögerte $acks$ geben nur Auskunft über auftretenden Datenstau. Sie können nicht anzeigen, ob die volle Bandbreite einer Verbindung auch wirklich
ausgenutzt wird. Daher sollte die Größe der Staufenster nach einem bestimmten Schema angehoben werden. Die Anpassung von $cwnd$ geschieht nach folgendem Prinzip:
\begin{itemize}
  \item Nach jedem Timeout wird $cwnd$ halbiert.
  \item Nach jedem $ack$ für neue Daten wird $cwnd$ um $1/cwnd$ erhöht.
  \item Beim Senden wird das Minimum an Daten von $cwnd$ und dem ``receivers advertised window'' gesendet.
\end{itemize}

Dieser Algorithmus trägt zur Stauvermeidung (``congestion avoidance'') bei und besteht parallel zum ``slow-start''-Algorithmus. Van Jacobson gibt in
\cite{jacobson88congestion} ein Auswahlkriterium an, nachdem zustandsabhängig zwischen beiden Algorithmen ausgewählt wird.

\paragraph{Karn's clamped retransmit backoff:}
\label{csp:karns_algorithmus}
Sequenznummern ermöglichen die Zuordnung eines $acks$ zu dem entsprechenden Datenpaket. Kommt es aufgrund von Timeouts zu Wiederholungen
desselben Datenpaketes, so tritt ein Problem auf, welches Karn und Partridge in \cite{Karn1991} als ``retransmission ambiguity'' bezeichnen:
es kann nicht festgestellt werden, auf welche Aussendung desselben Datenpaketes sich das $ack$ bezieht. Damit ist nicht klar, anhand welches Paketes
sich der $rtt$ bestimmen soll, er wird in jedem Falle nicht verlässlich sein. Verschiedene Protokollimplementationen behandeln dieses Problem
auf unterschiedliche Weise: teils wird die am längsten zurückliegende Aussendung als Grundlage zur Berechnung herangezogen, teils die am kürzesten zurückliegende
Aussendung.\\

Wird die am längsten zurückliegende Aussendung  gewählt, so können der $rtt$, damit der $srtt$ und letztlich der $rto$ unverhältnismäßig in die Höhe schießen.
In vielen Fällen ist die nachteilige Wirkung nicht besonders groß, da aufgrund des Datenstaus eine Drosselung der Datentransferrate erwünscht ist.
Kommt es aufgrund anderer Ursachen zu Paketverlusten (z. B. bei verlustreichen Leitungen durch Störsignale), so tritt das Gegenteil des gewünschten Verhaltens
ein: der $srtt$ sinkt auf ein sehr niedriges Niveau, obwohl sich in diesem Falle die Datentransferrate erhöhen sollte.\\

Wird die am kürzesten zurückliegende Aussendung herangezogen, so ist die Wahrscheinlichkeit laut Karn sehr groß, dass die Zeitfolge zwischen dieser Sendung und dem
ankommenden $ack$ sehr kurz ist, obwohl sich das $ack$ auf eine weiter zurückliegende Sendung bezieht. Dies führt zu einer drastischen Reduzierung des $srtt$,
was überflüssige Wiederholungen und damit eine zusätzliche Verschwendung der Bandbreite zur Folge hat \cite{Karn1991,Jain1986}. Andere Implementationen
lassen den $rtt$ bei Wiederholungen außer acht. Dies geht gut, solange der $rto$ nicht schneller ansteigt, als der Algorithmus sich adaptieren kann. Ist $\beta$
gut gewählt, so ist die Möglichkeit dafür sehr gering. Tritt dieser Fall dennoch ein, so kommt es (wie im letztgenannten Fall) zu überflüssigen Wiederholungen.\\

Um diesem Problem zu begegnen, schlägt Karn folgenden Algorithmus vor \cite{Karn1991}:\\
Grundsätzlich wird der $rto$ nach einem Timeout vergrößert (``back-off'').
Erreicht ein $ack$ den Sender nach einer Wiederholung eines Datenpaketes, so wird keine Neuberechnung des $rtt$ und $srtt$ vorgenommen. Dafür wird der neu
ermittelte (``backed-off'') $rto$ als Grundlage für die nächste Wiederholung bzw. für die Aussendung des nächsten Datenpaketes herangezogen. Nur wenn ein $ack$
den Sender ohne vorausgehende Wiederholung erreicht, wird der $rto$ mit Hilfe des nun neu berechneten $srtt$ ermittelt.\\
Die Wahl des neuen $rto$ im Falle einer Wiederholung muss laut Karn so erfolgen, dass der $rto$ größer ist als die tatsächliche Roundtrip-Time. Typischerweise
geschieht die Steigerung des $rto$ exponentiell (entsprechend des ``exponential retransmit timer backoff'', s. o.).

\paragraph{fast retransmit:}
Erreichen den Sender vier identische $acks$ in Folge, so wird der Sender das vom Empfänger erwartete Datenpaket sofort aussenden, ohne auf das
Ablaufen des Retransmission-Timers zu warten. ``Slow-start'' wird so lange ausgesetzt, bis ein anderes, nicht zu den vorherigen identisches $ack$ den Sender
erreicht  (\cite{RFC2581}). Die identischen $acks$ lassen sowohl darauf schließen, dass ein Datenpaket verloren gegangen ist, als auch, dass andere Datenpakete den
Empfänger höchstwahrscheinlich erreichen, da die identischen $acks$ sonst ausgeblieben wären. Die den identischen $acks$ zugrundeliegenden Datenpakete beeinflussen
das Datenaufkommen nicht mehr, da diese schon die Empfänger-Queue erreicht haben. Daher geht man davon aus, dass das erneute, schnelle Senden des fehlenden
Datenpaketes das Netz nicht wesentlich im Negativen beeinflusst. ``Fast retransmit'' sollte, muss aber nicht, von einer konkreten TCP-Implementation unterstützt
werden.\\

Zusätzliche Erweiterungen zum TCP in Hinsicht auf hohe Performanz finden sich in \cite{jacobson93tcp}.

\paragraph{Bezug zur Zielsetzung:}
Wie zu Beginn des Abschnittes motiviert, geht es darum, die Auslastung der Server-Queue stabil zu halten, bzw. dafür zu sorgen,
dass die Ungleichung $0\leq\rho<1$ erfüllt
ist.\\

Zeigen wir zunächst die Parallelen zwischen unserem Kommunikationsmodell und der Ebene, auf der TCP Anwendung findet: bei unserem Kommunikationsmodell
befinden sich die kommunizierenden Parteien (RSS-Server, Subscriber) ebenfalls an Endknoten. Befindet sich der RSS-Server unter starker Last, so wird seine
Antwort (die Übermittlung des RSS-Feeds) länger auf sich warten lassen, als unter geringerer Last. Die Roundtrip-Time zwischen Anfrage und dem vom RSS-Server
übermittelten Feed (entsprechend einem $ack$) lässt in gewissem Rahmen auf die Auslastung des Servers schließen. Auch in unserem Fall kann die Antwortzeit durch
eine starke Netzbelastung und dadurch verursachte
lange Übertragungszeiten negativ beeinflusst sein. Dies würde eventuell unser Ergebnis verfälschen, da wir nur an der Höhe der Serverlast interessiert sind.
Die Netzbelastung spielt für uns keine Rolle. Um Teillösungen zu finden, wollen wir aber zunächst von den Nachrichtenlaufzeiten abstrahieren. Auch in unserem
Fall muss der Subscriber, sollte die Server-Antwort ausbleiben, seine Anfrage erneut senden. Allerdings geschieht die Übermittlung eines RSS-Feeds per HTTP, welches
sich TCP als Übertragungsprotokoll bedient. TCP übernimmt die Steuerung des Datenflusses, weshalb wir uns um die wiederholte Aussendung von Datenpaketen
nicht zu kümmern brauchen. In folgenden Fällen ist jedoch das erneute Aussenden von Anfragen bzw. das Herstellen einer neuen TCP-Verbindung notwendig:
\begin{itemize}
\item nach einem Timeout wird die Verbindung unterbrochen, falls keine Reaktion vom Server erfolgt (Überlastung)
\item Die Verbindung kommt aufgrund einer Server-Überlastung gar nicht zustande (Anfrage findet keinen Eingang in die Server-Queue)
\end{itemize}
Für diese Fälle sollte der Subscriber ebenfalls einen Timer mitlaufen lassen. Der $rto$ bezeichnet hierbei das Zeitintervall bis zu einem erneuten
Verbindungsaufbau. Wie bei TCP sollte sich der $rto$ stetig vergrößern, um der Serverbelastung entgegenzuwirken.\\

Alle weiteren Überlegungen werden wir in Abschnitt \ref{css:staukontrolle_pubsubrss} treffen.

\subsubsection{Anwendung eines Regelkreises}
Die Aufgabe einer Regelung besteht darin, bestimmte Größen (Temperatur, Spannung, etc.) auf einen
vorgeschriebenen Wert zu bringen und diesen entgegen allen Störeinflüssen konstant zu halten (\cite{Bernstein1998}). Bei der Regelung unterscheidet man zwischen
verschiedenen Größen, die zusammen einen Regelkreis bilden: 
\begin{description}
  \item [Regelgröße $x$] oder auch der Istwert: Größe, welche konstant gehalten werden soll und zu diesem Zweck erfasst wird
  \item [Führungsgröße $w$] oder auch Sollwert: vorgegebener Wert, auf den die Regelgröße eingestellt werden soll
  \item [Störgröße $z:$] Größe, die die Regelgröße in unerwünschter Weise beeinflusst
  \item [Regeldifferenz $x_d:$] Differenz zwischen Führungs- und Regelgröße $x_d=w-x$
  \item [Stellgröße $y:$] Größe, durch welche die Regelgröße in erwünschter Weise beeinflusst wird
\end{description}

\begin{picturehere}{1}{4}{Regelkreis}{Abb:Regelkreis}
 \includegraphics[bb=180 0 682 141,scale=0.75]{Regelkreis}
\end{picturehere}

%\includegraphics[scale=0.75]{Regelkreis.pstex}

Bild \ref{Abb:Regelkreis} zeigt das vereinfachte Schema eines Regelkreises. Die Regelung basiert auf Rückkopplung. Bewirkt der Einfluss der Störgröße eine
Abweichung der Regelgröße von der Führungsgröße, so ergibt die Regeldifferenz über einen Regler eine Stellgröße, die entgegengesetzt zur Störgröße auf die
Regelgröße einwirkt. Ziel dabei ist es, die Regeldifferenz auf Null zu bringen.\\
Die Wahl eines geeigneten Reglers hängt stark von der Regelstrecke ab. Die Regelstrecke bezeichnet die zu regelnde Anlage oder den zu regelnden Prozess. Wichtig zu
wissen ist, wie die Regelstrecke auf Änderung der Einflussgrößen reagiert. Nach \cite{Bernstein1998} kann man die Regelstrecken grob durch folgende Merkmale 
unterscheiden:
\begin{itemize}
  \item Regelstrecken mit und ohne Ausgleich
  \item Regelstrecken mit und ohne Totzeiten bzw. Zeitgliedern
  \item lineare oder nichtlineare Regelstrecken
\end{itemize}

Bei Regelstrecken mit Ausgleich erreicht die Ausgangs- bzw. Regelgröße nach einer gewissen Zeit einen stabilen Zustand (Bsp. Raumtemperatur). Existiert kein
stabiler Zustand (Regelstrecke ohne Ausgleich), so ändert sich bei konstanter Eingangs- bzw. Stellgröße die Regelgröße mit
konstanter Geschwindigkeit oder Beschleunigung (Bsp. Füllen eines Wasserbehälters). Totzeit bezeichnet eine Zeitverzögerung, bis sich die Änderung der Stellgröße
auf die Regelgröße bemerkbar macht. Bei linearen Regelstrecken folgt die Regelgröße der Stellgröße proportional.

Meist liegt eine Kombination dieser Eigenschaften vor. Um die Stellgröße entsprechend der Regeldifferenz anzupassen, wird ein Regler benötigt.

\paragraph{PID-Regler:}
Ein PID-Regler ist ein allgemeiner Reglertyp, der häufig für Regelungen Verwendung findet. Er ist eine Kombination aus einem P-, einem I- und einem D-Regler.
Ein P-Regler sorgt dafür, dass (im stationären Zustand) ein dem Eingangssignal proportionales Ausgangssignal geliefert wird (unter Zuhilfenahme eines
Verstärkungsfaktors). Ein I-Regler summiert die Regeldifferenz über einen gewissen Zeitraum und führt damit eine Integration aus. Je länger eine Regeldifferenz
besteht, desto größer wird die Stellgröße. Ein D-Regler reagiert nur auf die Änderungsgeschwindigkeit der Regeldifferenz. Er liefert einen entsprechend starken,
kurzen, positiven Impuls.

Die allgemeine mathematische Gleichung für einen PID-Regler lautet wie folgt
(siehe \cite{WBuettner1991}):
\begin{equation}
  u(t)=K_R\left[\quad e(t) \quad + \quad
    \frac{1}{T_I}\int\limits_{0}^{t}e(\tau)d\tau \quad + \quad
    T_D\frac{de(t)}{dt} \quad \right]
\end{equation}

Die einzelnen Größen sind:
\begin{description}
  \item [$u(t)$] Stellgröße
  \item [$e(t)$] Regeldifferenz
  \item [$K_R$] Verstärkungsfaktor
  \item [$T_I$] Integrationskonstante
  \item [$T_D$] Differentiationskonstante
\end{description}

Es werden nicht für alle Regelungen alle Anteile benötigt. Durch Weglassen der entsprechenden Anteile erhält man die Regler P, PI bzw. PD. Reine P-Regler finden
nur Verwendung bei Regelstrecken linearen Verlaufs. Doch selbst hier zeigt sich, dass bei Regelabweichungen, die durch eine Störgröße hervorgerufen werden, die
Störgröße lediglich in ihrer Wirksamkeit gemindert werden kann. Eine vollständige Beseitigung tritt nicht ein, da die Regelabweichung selbst notwendig ist, um eine
Verstellung des Stellgliedes vorzunehmen \cite{Bernstein1998}. Mit einem I-Regler kann man die Regelabweichung sehr genau unterbinden, jedoch arbeitet dieser
relativ langsam und neigt zu Schwingungen. Die Vorteile beider Reglertypen vereint der PI-Regler. Reine D-Regler finden in der Praxis keine Verwendung, da sie bei
stabiler Regelgröße nicht in den Regelvorgang eingreifen können. Die Kombination mit einem P-Regler (also ein PD-Regler) bewirkt ein schnelleres Anspringen der
Regelung bei plötzlicher Regelabweichung im Vergleich zu einem reinen P-Regler.

\paragraph{Bezug zur Zielsetzung:}
Wir können die Erfüllung der Ungleichung $0\leq\rho<1$ durch einen Regelkreis beschreiben. Die zu regelnde Größe ist dabei $\rho$. Die Stellgröße
ist $cpp$. Aus Sicht eines Klienten
sind die $cpp$s der übrigen Klienten eine Störgröße, da ihre Veränderung die Auslastung des Servers beeinflusst. Bei der Regelstrecke handelt es
sich im Allgemeinen um einen nicht-linearen Typ mit Ausgleich und Totzeit. Als Regler sollten wir daher einen PI-Regler verwenden. Eine differentiale Eigenschaft
wollen wir zunächst außer Acht lassen, da diese nur zur Feinabstimmung beiträgt.\\

Um $\rho$ messen zu können, muss der Regler einen direkten Zugriff auf die Werte $\lambda$ und $\bar x$ (s.o.) erhalten können.
Dies ist aber im Allgemeinen bzw. bei unserem
favorisierten Ansatz nicht möglich, da nur der Server diese Werte ermitteln kann und diese entsprechend des Konzeptes nicht an die Klienten übermittelt.
Ein Klient kann somit nur aufgrund anderer Indizien auf diese Werte rückschließen.
Das einzige Indiz ist das Antwortverhalten bzw. die Antwortzeit des Servers auf eine Anfrage des Klienten. Abstrahieren wir von den Nachrichtenlaufzeiten,
so lässt eine lange Antwortzeit des Servers auf einen gewissen Überlastungsgrad schließen. Mit Hilfe der $rtt$ können wir somit die $cpp$ bestimmen, also
$cpp=f\cdot rtt$, wobei $f$ ein beliebiger Faktor ist (proportionaler
Anteil des Reglers). Eine konstante Abtastrate wäre wünschenswert, damit ein Regler zu jedem
Zeitpunkt die gleiche Reaktionszeit zeigen kann. Falls wir nur mit den regulären Anfragen nach RSS-Feeds zur Bestimmung der Server-Antwort arbeiten,
bewirkt eine Drosselung des $cpp$ ebenfalls eine Drosselung der Abtastrate.
Man könnte die Reaktionszeit des Servers anders ermitteln, z. B. durch konstantes Anpingen (z. B. mit Hilfe des Kommandos ``ping'').
Dies hätte jedoch u. a. zur Folge, dass dadurch bei einer großen Anzahl von Klienten im Overlay-Netzwerk ebenfalls
eine Server-Überlastung erreicht werden könnte. Die Beobachtung der zu regelnden Größe würde diese also gleichzeitig beeinflussen. Außerdem erreicht ein Ping
nicht die Anwendungsschicht des Servers, eine Überlastung auf dieser Ebene bleibt eventuell unbemerkt. Des Weiteren kann es vorkommen,
dass eine Anfrage eines Klienten bei voller Queue vom Server verworfen wird. Eine Server-seitige Antwort wird in diesem Fall ausbleiben. Nach einem
Timeout muss also der Klient seine Anfrage erneut stellen. Ist dieses Timeout konstant und relativ klein, so kann dies ebenfalls zu einer Mehrbelastung des Servers
führen. Hierbei kommt das für den Regler erforderliche Ereignis (Server-Antwort) gar nicht zustande, somit kann eine Regelung über den Regler gar nicht in der
gewünschten Weise stattfinden. Das Indiz für eine gesteigerte Server-Belastung ist hier also eine Negativ-Nachricht: das Ausbleiben der Server-Antwort. Um die
Mehrbelastung des Servers in diesem Fall einzudämmen, können wir die Timeouts und somit die $ccp$ je nach Zeitdauer vergrößern (integrativer Anteil,
vgl. Abschnitt \ref{css:tcp}).\\

Es zeigt sich, dass das Konzept des PID-Reglers nur modifiziert anwendbar auf unsere Problemstellung ist.
Wie schon angedeutet, werden wir die Grundideen eines PID-Reglers in unserer hergeleiteten Methode wiederfinden.

\subsubsection{Grundsätzliches zu Timern}
\label{css:timer}
\todo{folgt}

\subsubsection{Staukontrolle bei Pub/Sub-RSS}
\label{css:staukontrolle_pubsubrss}
Wir fassen kurz zusammenfassen, welche primären Ziele und damit verbundenen sekundären Ziele wir verfolgen: grundsätzlich geht es um die Bestimmung des Wertes
$ttr$ eines Subscribers (siehe Abschnitt \ref{cs:der_grundlegende_algorithmus}).
Zur Erinnerung: $ttr$ bezeichnet ``time-to-refresh'', also den konkreten Zeitpunkt, zu dem die nächste Anfrage an den jeweiligen RSS-Server
gestellt werden soll. Um $ttr$ zu bestimmen benötigen wir $\varDelta ttr$. Ein wichtiger Parameter zur Bestimmung von $\varDelta ttr$ ist der $cpp$. Um einer
längerfristigen
Überlastung des RSS-Servers entgegenzuwirken, muss der $cpp$ eines Subscribers entsprechend der Serverbelastung angepasst werden.
Wir müssen also ein Maß für die Serverbelastung bestimmen, was auch bei uns die ``Roundtrip-Time'' sein soll, also die Zeit, die zwischen Aussendung
einer Anfrage und dem Erhalt des entsprechenden Feeds vergeht. Die Roundtrip-Time ist jedoch nicht immer eindeutig zu bestimmen.
Im Folgenden soll der Wert $rtt$ den Näherungswert an die Roundtrip-Time bezeichnen, den es zu berechnen gilt.
Mit Hilfe von $rtt$ können wir dann $rto$ und $cpp$ ermitteln.\\

Der konzeptionelle Unterschied zwischen $rto$ und $cpp$ ist folgender: während der $cpp$ zur Berechnung des $\varDelta ttr$ bei erfolgreicher Anfrage
(also nach Erhalt eines RSS-Feeds) beiträgt, dient der $rto$ zur Berechnung des $\varDelta ttr$ bei erfolgloser Anfrage, also nach Ablauf des
``Retransmission-Timers'' ohne Erhalt eines
RSS-Feeds. Ob wir diese Werte separat berechnen, oder ob wir einen funktionalen Zusammenhang zwischen diesen Werten herstellen, werden wir im Folgenden erörtern.

Bei TCP gibt es ebenfalls eine funktionale Unterscheidung zwischen $srtt$ und $rto$,
wobei der $cpp$ hier für den $srtt$ bei TCP steht. Im Unterschied zu TCP bilden die verschiedenen Anfragen jedoch keinen Datenstrom. Der Wert $cpp$
reicht als Timeout-Intervall für die nächste Anfrage nicht aus. In unserem Fall muss die Zeit
bis zum Aussenden der nächsten Anfrage $\varDelta ttr$, die sich mit Hilfe von $cpp$ berechnet, ermittelt werden.\\

Beim Anpassen des $cpp$ muss berücksichtigt werden, dass grundsätzlich nicht ein Subscriber alleine für eine Überlastung verantwortlich ist, sondern in den
meisten Fällen eine Menge von Subscribern, die gemeinsam auf den gleichen RSS-Server zugreifen. Eine Senkung des $cpp$ kann also eine drastische Wirkung haben,
da je nach Verfahren eventuell jeder beteiligte Subscriber diese Maßnahme ergreift.\\

Zur Berechnung des $rtt$ müssen die RSS-Feeds nach ihrem Ursprung unterschieden werden: Feeds, die ein Subscriber von einem Broker erhält, müssen anders behandelt
werden als Feeds, die von einem RSS-Server ausgesandt werden. Für die Berechnung des $rtt$ spielen nur diese Feeds eine Rolle, da nur diese Auskunft über eine
eventuelle Server-Belastung geben können.\\

In den vorhergehenden Abschnitten wurden mögliche Techniken zur Staukontrolle und -vermeidung bei TCP und bei der Regelungstechnik vorgestellt,
und wir haben dabei festgestellt, dass die dort beschriebenen Lösungsansätze nur bedingt auf unser Problem anwendbar sind.
Im Folgenden wollen wir eine Lösung aufgrund einer problemorientierten Sichtweise konzipieren und dort Bezüge zu den beiden anderen Konzepten herstellen,
wo es angebracht erscheint.\\

Wie schon erwähnt übernimmt bei einer Anfrage an einen RSS-Server die TCP-Schicht die  Datenfluss- und Staukontrolle, so dass sich die Anwendungssoftware an
dieser Stelle nicht um wiederholte Aussendungen von Anfragen zu kümmern braucht. Wird eine TCP-Verbindung jedoch unterbrochen bzw.
kommt sie gar nicht zustande, so muss die
Anwendungssoftware den Verbindungsaufbau nach einer gewissen Zeit wiederholen. Die Zeit, die in diesem Fall bis zum nächsten Verbindungsaufbau vergehen soll,
wird durch $rto$ bestimmt. Das Problem der ``retransmission-ambiguity'' (siehe \ref{csp:karns_algorithmus}) kann nicht eintreten. Soll ein Verbindungsaufbau zu
einem RSS-Server geschehen, so sprechen wir im Folgenden der Einfachheit halber von der Aussendung eines ``Feed-Requests''.\\
Erhält ein Subscriber
einen Feed, so muss in jedem Fall der $ttr$ für die Aussendung des nächsten Feed-Requests berechnet und ein entsprechender
Timer $RQT$ (für ``Request-Timer'') eingerichtet werden, nach dessen Ablauf der Feed-Request versendet wird. Nach Aussendung des Feed-Requests muss nun ein
Timer $RT$ (für ``Retransmission-Timer'') eingerichtet werden, nach dessen Ablauf der Feed-Request erneut ausgesandt wird. Die Unterscheidung der beiden Timer
ist rein konzeptioneller Natur, in der Praxis können wir sagen: $RT:=RQT$, der $RQT$ wird dann je nach Situation unterschiedlich gesetzt. Um eine klarere
Differenzierung vorzunehmen, werden wir trotzdem dort zwischen den Begriffen $RQT$ und $RT$ unterscheiden, wo es der Deutlichkeit halber angebracht erscheint.
Mitbestimmend für den $RQT$ ist der $cpp$, mitbestimmend für den $RT$ der $rto$. $cpp$ wird ebenfalls je nach Situation unterschiedlich berechnet.

\paragraph{Berechnung von $rto$ und $rtt$:}
Der $rtt$ kann nur gemessen werden, wenn ein Subscriber einen RSS-Feed von einem RSS-Server zugesandt bekommt. Das setzt voraus, dass zuvor eine Anfrage an den
RSS-Server gestellt und dabei der $RT$ gesetzt wurde.
Bestimmend für den $RT$ ist der $rto$, welcher initial und bei Erhalt eines vom RSS-Server direkt versendeten Feeds auf $rto:=cpp$ gesetzt wird.
Bei jeder Aussendung eines Feed-Requests wird
zunächst der $rto$ verdoppelt und $RT$ neu gesetzt. Dies bedeutet exponentielles Wachstum des $rto$. Damit das System skalierbar ist und die Adaption auch bei
großen Netzen noch in angemessener Zeit geschieht, muss die
Anpassung exponentiell erfolgen (siehe ``exponential retransmit timer backoff'' in Abschnitt \ref{css:tcp}).\\
Erhält ein Subscriber einen RSS-Feed von einem RSS-Server, so muss die Roundtrip-Time bestimmt werden. Der Inhalt des Feeds erreicht den Subscriber aufgrund der
auf einer tieferen Ebene liegenden TCP-Schicht als Datenstrom. Hierbei können wir die Zeit zwischen Verbindungsaufbau und erstem erhaltenen Byte messen,
um die Roundtrip-Time zu bestimmen, welche durch den Wert $rtt$ festgehalten wird.
Muss es allerdings zu mehrfachen Versuchen kommen, eine Verbindung aufzubauen, so reicht diese gemessene Roundtrip-Time für die Besimmung von $cpp$ nicht aus.
Die Notwendigkeit mehrfacher Versuche lässt auf eine Überlastung des Servers schließen, so dass der $cpp$-Wert entsprechend angepasst werden muss. Daher soll
$rtt$ nicht die eigentliche Roundtrip-Time bezeichnen, sondern in $rtt$ müssen die mehrfachen Verbindungsversuche mit einfließen. Bezeichne $t_{V_1}$ den Zeitpunkt
des ersten Verbindungsversuches und $t_B$ den Zeitpunkt des ersten auftretenden Datenbytes, so bestimmt sich $rtt$ wie folgt:
\begin{equation}
rtt:=t_B - t_{V_1}.
\end{equation}

Experimente haben gezeigt, dass der so berechnete Wert $rtt$ für die Berechnung von $cpp$ nicht ausreicht, um eine gute Adaption an die Serverbelastung zu bewirken.
Daher definieren wir einen weiteren Wert
(eine skalierte Version des $rtt$-Wertes), den $artt$ (``adjusted roundtrip-time''), mit
\begin{equation}
artt:=sf(i)\cdot rtt.
\end{equation}

Dabei ist $sf()$ die Skalierungsfunktion und $i$ die Anzahl der ausgesendeten Anfragen bzw. die Anzahl der Verbindungsversuche bis zu einer erfolgreichen Verbindung.
Experimente mit Hilfe der entwickelten Simulationsumgebung haben gezeigt, dass eine polynomielle Skalierungsfunktion (quadratisch) ein
besseres Adaptionsverhalten als eine lineare Skalierung ermöglicht. Bei starker Serverbelastung hingegen sind Nebenwirkungen durch die polynomielle Skalierung
geringer als bei einer exponentiellen Skalierung. Dabei muss man berücksichtigen, dass die Berechnung des $rtt$-Wertes sowieso schon auf exponentieller Basis
geschieht, da der für Wiederholungen relevante $rto$-Wert exponentiell gesteigert wird. Wir definieren also \todo{exponentiell}
\begin{equation}
sf(x):=x^2.
\end{equation}

Hier kann man eine Analogie zum Konzept der PI-Reglern herstellen (obwohl es nur Parallelen in den Grundideen gibt): während man den $rtt$-Wert
als proportionalen Anteil in der Berechnung auffassen kann, entspricht die Skalierungsfunktion $sf()$ dem integrativen Anteil beim PI-Regler,
da diese die zeitliche Dauer der Server-Antwort berücksichtigt.\\

Bei Eintritt des Subscribers in das System wird $artt:=ppp$ gesetzt. 

\paragraph{Berechnung von $cpp$:}
Grundsätzlich dient der Wert $artt$ als Bezugspunkt für $cpp$.
Eine untere Schranke für den Wert $cpp$ soll $ppp$ bilden. Da jeder Subscriber $ppp$ individuell festlegen kann, ist es nicht notwendig,
$cpp$ kleiner als $ppp$ zu wählen.
Das heißt nicht, dass ein Subscriber frühestens nach Ablauf der Zeit $ppp$ einen neuen Feed bekommt: existieren im gleichen Netzwerk andere Subscriber, die einen
niedrigeren $ppp$ eingestellt haben, so kann jener Subscriber davon profitieren, da ihm dann ebenfalls neu auftretende Feeds nach kürzerer Zeit zugestellt werden.
Möchte ein Subscriber sicher gehen, dass ein bestimmter Aktualitätsgrad der Feeds erreicht wird, so muss er den $ppp$ entsprechend setzen.\\

Wir wollen ebenfalls eine obere Schranke für den Wert $cpp$, den $mpp$ (für maximale Polling-Periode), definieren. Dieser vermeidet, dass bei ungünstigen
Konstellationen der $cpp$ zu groß wird (z. B. wenn jeder Feed-Request eines Subscribers vom RSS-Server verworfen wird, obwohl der Server nicht stark
überlastet ist). Dieser sollte abhängig vom jeweiligen Overlay-Netzwerk bestimmt werden.\\

Bei jeder Änderung von $artt$ berechnet sich $cpp$ wie
folgt:
\begin{equation}
  cpp:=min\{mpp,max\{artt,ppp\}\}.
\end{equation}
Ein Varianzfaktor wird hierbei nicht hinzugezogen. Berechnungen auf dieser Grundlage
lieferten in der Simulation gute Ergebnisse. Eine Optimierung wäre eventuell möglich, wenn man einen Varianzfaktor entsprechend der $rto$-Berechnung bei
TCP hinzuzieht. Dies soll aber nicht Gegenstand dieser Arbeit sein und bleibt offen für weitere Forschungen.
Neuberechnungen von $cpp$ und $artt$ finden zunächst nur dann statt, wenn ein Subscriber einen RSS-Feed von einem RSS-Server erhält.
Weitere Verbesserungen werden wir in Abschnitt \ref{cs:ausbalancierung_der_polling-perioden} betrachten.

\paragraph{Ungenauigkeiten und Probleme:}
Ein Problem ist denkbar, welches sich auch in der Simulation gezeigt hat: einige wenige Subscriber, welche Anfragen mit einer hohen Frequenz aussenden (also
bei einer sehr kleinen Polling-Periode), können die übrigen Subscriber ``aussperren''. Die Subscriber, welche eine kürzere Polling-Periode berechnet haben, können
diese halten, da ihre Anfragen (bedingt durch deren Menge) eine größere Chance haben, in der Server-Queue zu landen. Die Queue wird unter diesen wenigen
Subscribern aufgeteilt. Somit erhalten sie die Feeds als Antwort auch mit einer höheren Frequenz vom Server. Dabei muss man bedenken,
dass sich die Anfragen mehrfacher Wiederholungen in der Server-Queue befinden können. Diese werden
nach und nach bearbeitet, Feeds werden an den jeweiligen Subscriber geschickt. Eine eventuelle Messung der Roundtrip-time wird dadurch verfälscht, so dass der
Subscriber (in der Annahme, der Server kann der Beantwortung einer Anfrage schnell nachkommen) seinen $cpp$ konstant halten kann. Die Polling-Perioden der
übrigen Subscriber wachsen dagegen drastisch. Denn gerade durch den Umstand, dass ihre
Anfragen seltener in der Server-Queue landen, werden sie durch die daraufhin verzögerten (oder ausbleibenden) Antworten ihre Polling-Perioden vergrößern.
Dieser Rückkopplungseffekt führt dazu, dass ihre Polling-Perioden dauerhaft große Werte aufweisen und für diese Subscriber kaum Chancen bestehen,
Feeds vom Server zu erhalten. Natürlich bekommen diese Subscriber ebenfalls die Feeds über das Netzwerk zugesandt. Die Polling-Perioden der verschiedenen Subscriber
sind aber stark auseinander gerissen, sie befinden sich in Dysbalance, wobei keine Änderungen der Polling-Perioden mehr zu erwarten sind.
Verlassen nun die Subscriber mit einer kurzen Polling-Periode das Netz, so steht dieses
zunächst fast still, da die restlichen Subscriber Anfragen erst nach einer großen Zeitdifferenz erneut aussenden. Wie man dieser Dysbalance entgegenwirken kann,
werden wir in Abschnitt \ref{cs:ausbalancierung_der_polling-perioden} darstellen.\\

Ein \label{cssp:ung_u_probl:dysbalance} weiterer eventuell problematischer Punkt (im obigen Absatz bereits angesprochen) ist die Berechnung des Wertes $artt$,
falls $RT$ noch nicht abgelaufen ist. In diesem Fall wird bei unserer Berechnung
der $artt$ direkt auf die gemessene Roundtrip-Time gesetzt, während bei TCP diese nur zum Teil (unter zusätzlicher Zuhilfenahme des Glät\-tungs\-fak\-tors $\alpha$,
siehe Abschnitt \ref{cssp:tcp_rtt}, Seite \pageref{cssp:tcp_rtt}) in die Berechnung eingeht. Diese direkte Rück\-setzung könnte zu einem starken Schwingungsverhalten der
Server-Belastung und somit der Polling-Perioden im System führen. Allerdings ist eine schnelle Reaktion des Systems auf eine
verbesserte Server-Reaktionsfähigkeit erwünscht, und in der Mehrheit der Fälle werden nicht alle Subscriber gleichzeitig den Wert $artt$ auf diese Weise ermitteln.
Beobachtungen zeigen jedoch, dass es bei einer plötzlichen Erreichbarkeit des Servers tatsächlich zu einem Ansturm
auf diesen kommen kann. Wir werden aber
dieses Phänomen in Zusammenhang mit der vorgestellten Technik in Abschnitt \ref{cs:ausbalancierung_der_polling-perioden} eindämmen können. 


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "diplomarbeit"
%%% End: 
