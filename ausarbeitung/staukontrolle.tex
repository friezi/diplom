
\subsection{Staukontrolle}
Seitdem Computer-Netzwerke explosionsartig an Größe und Komplexität zugenommen haben, hat sich ein Problem verstärkt bemerkbar gemacht: Datenstau.
Van Jacobson et. al. (\cite{jacobson88congestion}) schildert die Beobachtung, dass in der Zeit mitte der 1980er Jahre Internet-Gateways 10\% der
ankommenden Pakete aufgrund von Pufferüberläufen verwarfen. Laut seiner Aussage lag dabei das Problem nicht in den Protokollspezifikationen selbst, sondern
hauptsächlich in deren Implementierungen. TCP (Transmission Control Protocol) ist ein verbindungsorientiertes Transportprotokoll, mit dessen Hilfe der Großteil
des Netzwerkverkehrs vonstatten geht. Im Laufe der Zeit wurden in TCP Mechanismen eingebaut und verbessert, um Datenstau festzustellen und soweit wie möglich
zu vermeiden.\\

Auf dem Gebiet der Regelungstechnik beschäftigt man sich damit, wie eine Größe einen bestimmten vorgegebenen Wert erreichen und halten kann. Bei einer Regelung
finden Kontrollmechanismen
Anwendung, um Wertabweichungen festzustellen und auszugleichen.\\

Im Folgenden werden wir Techniken aus diesen Teilgebieten betrachten und diese auf ihre Tauglichkeit bezüglich der Lösung unseres beschriebenen Problems untersuchen.
Nicht alle der vorgestellten Techniken sind ohne weiteres auf unsere Problemstellung anwendbar, und wir werden eine Lösung entwickeln, die auf die konkrete
Problemstellung unter Berücksichtigung der gegebenen Umstände zurecht geschnitten ist.

\subsubsection{Staukontrolle bei TCP}
\label{css:tcp}
TCP (Transmission Control Protocol) ist ein verbindungsorientiertes Über\-tra\-gungs\-pro\-to\-koll und kontrolliert die Datenübertragung zwischen Sender und
Empfänger der Endknoten. Dabei wird gewährleistet, dass jedes der einzelnen Datenpakete (die einen Datenstrom formen) den Empfänger erreicht
und die Ordnung der Pakete
innerhalb des Datenstroms bestehen bleibt. Bei Datenstau handelt es sich um Verlust von Datenpaketen. Falls es zu Datenstau kommt, so tritt dieser immer an
Verbindungsknoten (einschliesslich des Empfangsknotens) auf und kann durch verschiedene Faktoren auf dem Weg zwischen Sender und Empfänger hervorgerufen werden:
\begin{description}
  \item [Bandbreiten:]
    Unterschiedliche Bandbreiten auf dem Weg zwischen Sender und Empfänger beeinflussen die Übertragungsgeschwindigkeit einer Verbindung
    nachteilig in der
    Form, dass die ``langsamste'' Leitung (also die mit der geringsten Bandbreite) die
    Gesamt-Übertragungsgeschwindigkeit vorgibt. Trifft eine schnelle Leitung auf eine langsame Leitung, so können die an der langsamen Leitung ankommenden
    Pakete nicht schnell genug weiter geleitet werden. An diesem Knoten kommt es zum Pufferüberlauf, überschüssige Datenpakete gehen verloren.
  \item [Anzahl der Verbindungen:]
    An einem Knotenpunkt können mehrere Verbindungen zusammen kommen, die den Gesamt-Datenfluss an diesem Punkt erhöhen. Auch hier kann es zum Pufferüberlauf
    kommen, so dass überschüssige Datenpakete verloren gehen.
\end{description}
Damit jedes ausgesandte Paket den Empfänger erreicht, werden in TCP Bestätigungs-Nachrichten (Acknowledgements, im Folgenden kurz $acks$ genannt) versandt.
Erhält der Sender für ein gesendetes TCP-Datenpaket kein $ack$, so wird er das Datenpaket erneut senden. Ein wichtiger Bestandteil eines Datenpaketes ist
die Sequenznummer \cite{RFC2581}. Anhand der Sequenznummer kann ein $ack$ eindeutig einem versendeten Datenpaket zugeordnet werden. Innerhalb des $acks$ vermerkt
der Empfänger ebenfalls, welches Datenpaket er als nächstes erwartet \cite{RFC793}.
Um eine Staukontrolle zu erreichen wurden einige Algorithmen in TCP integriert (siehe \cite{jacobson88congestion}, wir halten uns dabei an die englischen
Bezeichnungen):
\begin{itemize}
  \item slow-start
  \item round-trip-time variance estimation
  \item exponential retransmit timer backoff
  \item more aggressive receiver ack policy
  \item dynamic window sizing on congestion
  \item Karn's clamped retransmit backoff
  \item fast retransmit
\end{itemize}

Dabei soll erreicht werden, dass die maximal mögliche Bandbreite (begrenzt durch die minimale Bandbreite (``bottleneck'') auf dem Verbindungsweg, s. o.) voll
ausgenutzt wird, ohne
dass Pakete verloren gehen; es darf also kein Paket in das Netzwerk eingespeist werden, bevor ein altes Paket entfernt wurde (die Verbindung befindet sich dann im
``Equilibrium'', der Paketfluss ist ``conservative'' \cite{jacobson88congestion}). Im Folgenden wollen wir die wichtigsten der oben genannten Algorithmen
vorstellen. Eine genaue Herleitung und Analyse der Algorithmen geht jedoch über den Rahmen dieser Arbeit hinaus.
Wir verweisen auf die entsprechenden Quellen in den Literaturangaben.

\paragraph{more aggressive receiver ack policy:}
\footnote{Hier ist in \cite{jacobson88congestion} nicht eindeutig feststellbar,  worauf sich van Jacobson genau bezieht, da er diese Bezeichnung im weiteren Text
nicht mehr verwendet. Es erschien sinnvoll, die folgende im o. g. Text zu findende Erklärung diesem Thema zuzuordnen.}TCP
ist ``self-clocking'': da $acks$ erst nach Erhalt der entsprechenden Datenpakete versendet werden können, bestimmt die Rate der ankommenden $acks$ die
Rate, mit der weitere Datenpakete ausgesendet werden sollen. Die Senderate passt sich somit automatisch der Bandbreite an.

\paragraph{slow-start:}
Durch das ``self-clocking'' tritt nur beim Start des Datentransfers ein Problem auf, da
hier zunächst eine feste Rate gewählt werden muss. Diese wird zu Beginn relativ niedrig gewählt, bzw. ein Staufenster ``congestion window'' ($cngw$) 
bestimmt die Anzahl der Pakete pro Sendevorgang. Bei Start des Transfers oder nach Paketverlust wird die Größe des Staufenster auf 1 gesetzt.
Für jedes $ack$ wird das Staufenster um den Betrag 1 erhöht. Begrenzt wird dessen Größe durch das ``advertised receiver window'',
welches vom Empfänger festgelegt wird und angibt, wieviele Bytes maximal als nächstes übersendet werden sollen. Die Zunahme der Größe $w$ des
Staufensters geschieht in der Zeit
$rtt*log_2w$, wobei $rtt$ die ``round-trip-time'' des letzten versendeten Datenpaketes ist (Zeit zwischen Versenden eines Datenpaketes und Erhalt des
entsprechenden $acks$). Siehe dazu \cite{jacobson88congestion}, \cite{RFC2581}. 

\paragraph{round-trip-time variance estimation:}
$Acks$ können die Geschwindigkeit des Datenflusses steuern, doch was geschieht, wenn $acks$ aufgrund verloren gegangener Pakete ausbleiben? Müssen sich
beispielsweise bei voll ausgenutzter Bandbreite plötzlich zwei Datenströme dieselbe Leitung teilen, kommt es bei gleichbleibender Datentransferrate mit Sicherheit zu
Paketverlusten und somit zu
ausbleibenden $acks$. Der Sender muss einen Timer unterhalten, bei dessen Ablauf das zuletzt gesendete Datenpaket erneut versendet wird (im Folgenden als
Retransmission bezeichnet). Paketverlust kann auch
durch Beschädigung der Daten während der Übermittlung auftreten. Nach van Jacobson \cite{jacobson88congestion} Liegt die Wahrscheinlichkeit dafür aber weit
unter 1\%. Daher lassen Timeouts bei gut eingestellten Timern mit sicherer Gewissheit auf Paketverluste schließen \footnote{Zur Problematik
bei Timern siehe \ref{css:timer}}. Diese Timeouts werden pro Verbindung dynamisch berechnet; im Folgenden bezeichnet $rto$ das ``retransmission timeout''-Intervall,
also die Zeitdifferenz bis zum nächsten Aussenden eines Datenpaketes. Entsprechend der TCP-Spezifikation
berechnet sich (siehe \cite{18216}):
\[rto=min(UBound, max(LBound, \beta * srtt))\]
$\beta$ ist dabei ein empirisch ermittelter Varianz-Faktor, $UBound$ und $LBound$ sind untere und
obere Schranke für den $rto$. $srtt$ ist die ``smoothed roundtrip time'' und wird wie folgt ermittelt:
\[srtt= \alpha * srtt+ (1 - \alpha) * rtt\] 
$\alpha$ ist ein ebenfalls empirisch ermittelter Glättungsfaktor (``smoothing factor''). Empfohlene Werte sind für $\alpha:$ $0.8 \sim 0.9$ und für $\beta:$
$1.3 \sim 2$ \cite{18216}.\\
Laut van Jacobson \cite{jacobson88congestion} liegt hierin folgende Problematik: $\beta$ kann sich höchstens an eine bis zu 30\% gesteigerte Last anpassen. Aber die
Varianz des Wertes $rtt$ steigert sich rapide mit ansteigender Last. Bei
Laststeigerung über die 30\%-Marke hinaus kommt es zu verspäteten $acks$. Der jeweilige abgelaufene Timer bewirkt eine Retransmission des entsprechenden
Datenpaketes, was zu unnötiger Mehrarbeit des Netzwerkes und zu Bandbreitenverschwendung führt. Daher wird $\beta$ ebenfalls dynamisch berechnet.
Eine Berechnungsmethode findet sich in \cite{jacobson88congestion}.

\paragraph{exponential retransmit timer backoff:}
Um den Datenstau durch mehrfach ausgesandte Pakete nicht noch zu vermehren, muss sich der $rto$ stetig vergrößern.
Van Jacobson \cite{jacobson88congestion} stellt heraus, dass nur exponentielles Wachstum des $rto$ Erfolg verspricht.
Daher wird nach jedem erneuten Aussenden eines nicht bestätigten Datenpaketes der $rto$ verdoppelt.

\paragraph{dynamic window sizing on congestion:}
Ein Vergrößern des $rto$ verhindert nur einen zusätzlichen Datenstau durch erneut ausgesandte Datenpakete. Damit auch die im Anschluss daran neu
ausgesandten Pakete nicht wieder zum Anstieg des Datenstaus führen, wird ebenfalls die Größe der Staufenster $cwnd$ halbiert (exponentielle Abnahme).
Ausbleibende oder verzögerte $acks$ geben nur Auskunft über auftretenden Datenstau. Sie können nicht anzeigen, ob die volle Bandbreite einer Verbindung auch wirklich
ausgenutzt wird. Daher sollte die Größe der Staufenster nach einem bestimmten Schema angehoben werden. Die Anpassung von $cwnd$ geschieht nach folgendem Prinzip:
\begin{itemize}
  \item Nach jedem Timeout wird $cwnd$ halbiert.
  \item Nach jedem $ack$ für neue Daten wird $cwnd$ um $1/cwnd$ erhöht.
  \item Beim Senden wird das Minimum and Daten von $cwnd$ und dem ``receivers advertised window'' gesendet.
\end{itemize}

Dieser Algorithmus trägt zur Stauvermeidung (``congestion avoidance'') bei und besteht parallel zum ``slow-start''-Algorithmus. Van Jacobson gibt in
\cite{jacobson88congestion} ein Auswahlkriterium an, nachdem zustandsabhängig zwischen beiden Algorithmen ausgewählt wird.

\paragraph{Karn's clamped retransmit backoff:}
Sequenznummern ermöglichen die Zuordnung eines $acks$ zu dem entsprechenden Datenpaket. Kommt es aufgrund von Timeouts zu Retransmissionen
desselben Datenpaketes, so tritt ein Problem auf, welches Karn und Partridge in \cite{Karn1991} als ``retransmission ambiguity'' bezeichnen:
es kann nicht festgestellt werden, auf welche Aussendung desselben Datenpaketes sich das $ack$ bezieht. Damit ist nicht klar, anhand welches Paketes
sich der $rtt$ bestimmen soll, er wird in jedem Falle nicht verlässlich sein. Verschiedene Protokollimplementationen behandeln dieses Problem
auf unterschiedliche Weise: teils wird die am längsten zurückliegende Aussendung als Grundlage zur Berechnung herangezogen, teils die am kürzesten zurückliegende
Aussendung.
Wird die am längsten zurück liegende Aussendung  gewählt, so können der $rtt$, damit der $srtt$ und letztlich der $rto$ unverhältnismäßig in die Höhe schießen.
In vielen Fällen ist die nachteilige Wirkung nicht besonders groß, da aufgrund des Datenstaus eine Drosselung der Datentransferrate erwünscht ist.
Kommt es aufgrund anderer Ursachen zu Paketverlusten (z. B. bei verlustreichen Leitungen durch Störsignale), so tritt das Gegenteil des gewünschten Verhaltens
ein: der $srtt$ sinkt auf ein sehr niedriges Niveau, obwohl sich in diesem Falle die Datentransferrate erhöhen sollte.
Wird die am kürzesten zurückliegende Aussendung herangezogen, so ist die Wahrscheinlichkeit laut Karn sehr groß, dass die Zeitfolge zwischen dieser Sendung und dem
ankommenden $ack$ sehr kurz ist, obwohl sich das $ack$ auf eine weiter zurückliegende Sendung bezieht. Dies führt zu einer drastischen Reduzierung des $srtt$,
was überflüssige Retransmissionen und damit eine zusätzliche Verschwendung der Bandbreite zur Folge hat (\cite{Karn1991},\cite{Jain1986}). Andere Implementationen
lassen die $rtt$ bei Retransmissionen außer acht. Dies geht gut, solange der $rto$ nicht schneller ansteigt, als der Algorithmus sich adaptieren kann. Ist $\beta$
gut gewählt, so ist die Möglichkeit dafür sehr gering. Tritt dieser Fall dennoch ein, so kommt es (wie im letztgenannten Fall) zu überflüssigen Retransmissionen.\\

Um diesem Problem zu begegnen, schlägt Karn folgenden Algorithmus vor \cite{Karn1991}:\\
Grundsätzlich wird der $rto$ nach einem Timeout vergrößert (``back-off'').
Erreicht ein $ack$ den Sender nach einer Retransmission eines Datenpaketes, so wird keine Neuberechnung des $rtt$ und $srtt$ vorgenommen. Dafür wird der neu
ermittelte (``backed-off'') $rto$ als Grundlage für die nächste Retransmission bzw. für die Aussendung des nächsten Datenpaketes herangezogen. Nur wenn ein $ack$
den Sender ohne vorausgehende Retransmission erreicht, wird der $rto$ mit Hilfe des nun neu berechneten $srtt$ ermittelt.\\
Die Wahl des neuen $rto$ im Falle einer Retransmission muss laut Karn so erfolgen, dass der $rto$ größer ist als die tatsächliche Roundtrip-Time. Typischerweise
geschieht die Steigerung des $rto$ exponentiell (entsprechend des ``exponential retransmit timer backoff'', s. o.).

\paragraph{fast retransmit:}
Erreichen den Sender vier identische $acks$ in Folge, so wird der Sender das vom Empfänger erwartete Datenpaket sofort aussenden, ohne auf das
Ablaufen des Retransmissionstimers zu warten. ``Slow-start'' wird so lange ausgesetzt, bis ein anderes, nicht zu den vorherigen identisches $ack$ den Sender
erreicht  (\cite{RFC2581}). Die identischen $acks$ lassen sowohl darauf schließen, dass ein Datenpaket verloren gegangen ist, als auch, dass andere Datenpakete den
Empfänger höchstwahrscheinlich erreichen, da die identischen $acks$ sonst ausgeblieben wären. Die den identischen $acks$ zugrundeliegenden Datenpakete beeinflussen
das Datenaufkommen nicht mehr, da diese schon die Empfänger-Queue erreicht haben. Daher geht man davon aus, dass das erneute, schnelle Senden des fehlenden
Datenpaketes das Netz nicht wesentlich im Negativen beeinflusst. ``Fast retransmit'' sollte, muss aber nicht von einer konkreten TCP-Implementation unterstützt
werden.\\

Zusätzliche Erweiterungen zum TCP in Hinsicht auf hohe Performanz finden sich in \cite{jacobson93tcp}.

\paragraph{Bezug zur Zielsetzung:}
Wie zu Beginn des Abschnittes gesagt, geht es darum, die Auslastung der Server-Queue stabil zu halten, bzw. dafür zu sorgen,
dass die Ungleichung $0\leq\rho<1$ erfüllt
ist. Zeigen wir zunächst die Parallelen zwischen unserem Kommunikationsmodell und der Ebene, auf der TCP Anwendung findet: bei unserem Kommunikationsmodell
befinden sich die kommunizierenden Parteien (RSS-Server, Subscriber) ebenfalls an Endknoten. Befindet sich der RSS-Server unter starker Last, so wird seine
Antwort (die Übermittlung des RSS-Feeds) länger auf sich warten lassen, als unter geringerer Last. Die $rtt$ zwischen Anfrage und dem vom RSS-Server übermittelten
Feed (entsprechend einem $ack$) lässt in gewissem Rahmen auf die Auslastung des Servers schließen. Auch in unserem Fall kann die Antwortzeit durch
ein starke Netzbelastung und dadurch verursachte
lange Übertragungszeiten negativ beeinflusst sein. Dies würde eventuell unser Ergebnis verfälschen, da wir nur an der Stärke der Serverlast interessiert sind,
die Netzbelastung spielt für uns keine Rolle. Um Teillösungen zu finden, wollen wir aber zunächst von den Nachrichtenlaufzeiten abstrahieren. Auch in unserem
Falle muss der Subscriber, sollte die Server-Antwort ausfallen, seine Anfrage erneut senden. Dafür sollte er ebenfalls einen Timer mit laufen lassen. Wie bei
TCP sollte sich der $rto$ stetig vergrößern, um die Serverbelastung nicht noch zu steigern. Erreicht die Server-Antwort den Subscriber
lediglich verspätet, nach dem die Anfrage bereits wiederholt gesendet wurde, kommt es hier in jedem Falle zum Problem der ``retransmission ambiguity'': der
Subscriber kann nicht zuordnen, auf welche Anfrage sich die Antwort bezieht,
da unser Ansatz keine Sequenznummern zulässt. In diesem Sinne gibt es bei unserem Ansatz keinen Unterschied zwischen regulären Anfragen und Retransmissionen von
Anfragen, da sich der Informationsgehalt der Anfragen grundsätzlich nicht unterscheidet. Ob wir an dieser Stelle Karns Lösung favorisieren oder eine andere Lösung
wählen, werden wir im Abschnitt \ref{css:staukontrolle_pubsubrss} erörtern.

\subsubsection{Anwendung eines Regelkreises}
Die Aufgabe einer Regelung besteht darin, bestimmte Größen (Temperatur, Spannung, etc.) auf einen
vorgeschriebenen Wert zu bringen und diesen entgegen allen Störeinflüssen konstant zu halten (\cite{Bernstein1998}). Bei der Regelung unterscheidet man zwischen
verschiedenen Größen, die zusammen einen Regelkreis bilden: 
\begin{description}
  \item [Regelgröße $x$] oder auch der Istwert: Größe, welche konstant gehalten werden soll und zu diesem Zweck erfasst wird
  \item [Führungsgröße $w$] oder auch Sollwert: vorgegebener Wert, auf den die Regelgröße eingestellt werden soll
  \item [Störgröße $z:$] Größe, die die Regelgröße in unerwünschter Weise beeinflusst
  \item [Regeldifferenz $x_d:$] Differenz zwischen Führungs- und Regelgröße $x_d=w-x$
  \item [Stellgröße $y:$] Größe, durch welche die Regelgröße in erwünschter Weise beeinflusst wird
\end{description}

\begin{picturehere}{1}{4}{Regelkreis}{Abb:Regelkreis}
 \includegraphics[bb=180 0 682 141,scale=0.75]{Regelkreis}
\end{picturehere}

%\includegraphics[scale=0.75]{Regelkreis.pstex}

Bild \ref{Abb:Regelkreis} zeigt das vereinfachte Schema eines Regelkreises. Die Regelung basiert auf Rückkopplung. Bewirkt der Einfluss der Störgröße eine Abweichung
der Regelgröße von der Führungsgröße, so ergibt die Regeldifferenz über einen Regler eine Stellgröße, die entgegengesetzt zur Störgröße auf die Regelgröße einwirkt.
Ziel dabei ist es, die Regeldifferenz auf Null zu bringen.

Die Wahl eines geeigneten Reglers hängt stark von der Regelstrecke ab. Die Regelstrecke bezeichnet die zu regelnde Anlage oder den zu regelnden Prozeß. Wichtig zu
wissen ist, wie die Regelstrecke auf Änderung der Einflussgrößen reagiert. Nach \cite{Bernstein1998} kann man die Regelstrecken grob durch folgende Merkmale 
unterscheiden:
\begin{itemize}
  \item Regelstrecken mit und ohne Ausgleich
  \item Regelstrecken mit und ohne Totzeiten bzw. Zeitglieder
  \item lineare oder nichtlineare Regelstrecken
\end{itemize}

Bei Regelstrecken mit Ausgleich erreicht die Ausgangs- bzw. Regelgröße nach einer gewissen Zeit einen stabilen Zustand (Bsp. Raumtemperatur). Existiert kein
stabiler Zustand (Regelstrecke ohne Ausgleich), so ändert sich bei konstanter Eingangs- bzw. Stellgröße die Regelgröße mit
konstanter Geschwindigkeit oder Beschleunigung (Bsp. Füllen eines Wasserbehälters). Totzeit bezeichnet eine Zeitverzögerung, bis sich die Änderung der Stellgröße
auf die Regelgröße bemerkbar macht. Bei linearen Regelstrecken folgt die Regelgröße der Stellgröße proportional.

Meist liegt eine Kombination dieser Eigenschaften vor. Um die Stellgröße entsprechend der Regeldifferenz anzupassen, wird ein Regler benötigt.

\paragraph{PID-Regler:}
Ein PID-Regler ist ein allgemeiner Reglertyp, der häufig für Regelungen Verwendung findet. Er ist eine Kombination aus einem P-, einem I- und einem D-Regler.
Ein P-Regler sorgt dafür, dass (im stationären Zustand) ein dem Eingangssignal proportionales Ausgangssignal geliefert wird (unter Zuhilfenahme eines
Verstärkungsfaktors). Ein I-Regler summiert die Regeldifferenz über einen gewissen Zeitraum und führt damit eine Integration aus. Je länger eine Regeldifferenz
besteht, desto größer wird die Stellgröße. Ein D-Regler reagiert nur auf die Änderungsgeschwindigkeit der Regeldifferenz. Er liefert einen entsprechend starken,
kurzen positiven Impuls (ein reiner D-Regler hat in der Praxis keine Bedeutung).

Die allgemeine mathematische Gleichung für einen PID-Regler lautet wie folgt (siehe \cite{WBuettner1991}):
\[u(t)=K_R\left[\quad e(t) \quad + \quad \frac{1}{T_I}\int\limits_{0}^{t}e(\tau)d\tau \quad + \quad T_D\frac{de(t)}{dt} \quad \right]\]

Die einzelnen Größen sind:
\begin{description}
  \item [$u(t)$] Stellgröße
  \item [$e(t)$] Regeldifferenz
  \item [$K_R$] Verstärkungsfaktor
  \item [$T_I$] Integrationskonstante
  \item [$T_D$] Differentiationskonstante
\end{description}

Es werden nicht für alle Regelungen alle Anteile benötigt. Durch weglassen der entsprechenden Anteile erhält man die Regler P, PI bzw. PD. Reine P-Regler finden
nur Verwendung bei Regelstrecken linearen Verlaufs. Doch selbst hier zeigt sich, dass bei Regelabweichungen, die durch eine Störgröße hervorgerufen werden, die
Störgröße lediglich in ihrer Wirksamkeit gemindert werden kann. Eine vollständige Beseitigung tritt nicht ein, da die Regelabweichung selbst notwendig ist, um eine
Verstellung des Stellgliedes vorzunehmen (\cite{Bernstein1998}). Mit einem I-Regler kann man die Regelabweichung sehr genau unterbinden, jedoch arbeitet dieser
relativ langsam und neigt zu Schwingungen. Die Vorteile beider Reglertypen vereint der PI-Regler. Reine D-Regler finden in der Praxis keine Verwendung, da sie bei
stabiler Regelgröße nicht in den Regelvorgang eingreifen können. Die Kombination mit einem P-Regler (also ein PD-Regler) bewirkt ein schnelleres Anspringen der
Regelung bei plötzlicher Regelabweichung im Vergleich zu einem reinen P-Regler.\\

\paragraph{Bezug zur Zielsetzung:}
Wir können die Erfüllung der Ungleichung $0\leq\rho<1$ durch einen Regelkreis beschreiben. Die zu regelnde Größe ist dabei $\rho$. Die Stellgröße
ist $cpp$. Aus Sicht eines Klienten
sind die $cpp$s der übrigen Klienten eine Störgröße, da ihre Veränderung die Auslastung des Servers beeinflusst. Bei der Regelstrecke handelt es
sich im allgemeinen um einen nicht-linearen Typ mit Ausgleich und Totzeit. Als Regler sollten wir daher einen PI-Regler verwenden. Eine differentiale Eigenschaft
wollen wir zunächst außer acht lassen, da diese nur zur Feinabstimmung beiträgt.\\

Um $\rho$ messen zu können, muss der Regler einen direkten Zugriff auf die Werte $\lambda$ und $\bar x$ (s.o.) erhalten können.
Dies ist aber im allgemeinen, bzw. bei unserem
favorisierten Ansatz nicht möglich, da nur der Server diese Werte ermitteln kann und diese entsprechend des Konzeptes nicht an die Klienten übermittelt.
Ein Klient kann somit nur aufgrund anderer Indizien auf diese Werte rückschließen.
Das einzige Indiz ist das Antwortverhalten bzw. die Antwortzeit des Servers auf eine Anfrage des Klienten. Abstrahieren wir von den Nachrichtenlaufzeiten,
so lässt eine lange Antwortzeit des Servers auf einen gewissen Überlastungsgrad schließen. Mit Hilfe der $rtt$ können wir somit die $cpp$ bestimmen, also
$cpp=f*rtt$, wobei $f$ ein beliebiger Faktor ist (proportionaler
Anteil des Reglers). Eine konstante Abtastrate wäre wünschenswert, damit ein Regler zu jedem
Zeitpunkt die gleiche Reaktionszeit zeigen kann. Falls wir nur mit den regulären Anfragen nach RSS-Feeds zur Bestimmung der Server-Antwort arbeiten,
bewirkt eine Drosselung des $cpp$ ebenfalls eine Drosselung der Abtastrate.
Man könnte die Reaktionszeit des Servers anders ermitteln, z. B. durch konstantes Anpingen (z. B. mit Hilfe des Kommandos ``ping'').
Dies hätte jedoch u. a. zur Folge, dass dadurch bei einer großen Anzahl Klienten im Overlay-Netzwerk ebenfalls
eine Server-Überlastung erreicht werden könnte. Die Beobachtung der zu regelnden Größe würde diese also gleichzeitig beeinflussen. Außerdem erreicht ein Ping
nicht die Anwendungsschicht des Servers, eine Überlastung auf dieser Ebene bleibt eventuell unbemerkt. Des Weiteren kann es vorkommen,
dass eine Anfrage eines Klienten bei voller Queue vom Server verworfen wird. Eine Server-seitige Antwort wird in diesem Falle ausbleiben. Nach einem gewissen
Timeout muss also der Klient seine Anfrage erneut stellen. Ist dieses Timeout konstant und relativ klein, so kann dies ebenfalls zu einer Mehrbelastung des Servers
führen. Hierbei kommt das für den Regler erforderliche Ereignis (Server-Antwort) gar nicht zustande, somit kann eine Regelung über den Regler gar nicht in der
gewünschten Weise stattfinden. Das Indiz für eine gesteigerte Server-Belastung ist hier also eine Negativ-Nachricht: das Ausbleiben der Server-Antwort. Um die
Mehrbelastung des Servers in diesem Fall einzudämmen, können wir die Timeouts und somit die $ccp$ je nach Zeitdauer vergrößern (integrativer Anteil,
vgl. Abschnitt \ref{css:tcp} TCP).\\

Es zeigt sich, dass das Konzept des PID-Reglers nur modifiziert anwendbar ist auf unsere Problemstellung.
Wie schon angedeutet, werden wir die Grundideen eines PID-Reglers in unserer hergeleiteten Methode wiederfinden.

\subsubsection{Staukontrolle bei Pub/Sub-RSS}
\label{css:staukontrolle_pubsubrss}
