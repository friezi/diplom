
\subsection{Staukontrolle}
Seitdem Computer-Netzwerke explosionsartig an Größe und Komplexität zugenommen haben, hat sich ein Problem verstärkt bemerkbar gemacht: Datenstau.
Van Jacobson et. al. (\cite{jacobson88congestion}) schildert die Beobachtung, dass in der Zeit Mitte der 1980er Jahre Internet-Gateways 10\% der
ankommenden Pakete aufgrund von Pufferüberläufen verwarfen. Laut seiner Aussage lag dabei das Problem nicht in den Protokollspezifikationen selbst, sondern
hauptsächlich in deren Implementierungen. TCP (Transmission Control Protocol) ist ein verbindungsorientiertes Transportprotokoll, mit dessen Hilfe der Großteil
des Netzwerkverkehrs vonstatten geht. Im Laufe der Zeit wurden in TCP Mechanismen eingebaut und verbessert, um Datenstau festzustellen und soweit wie möglich
zu vermeiden.\\

Auf dem Gebiet der Regelungstechnik beschäftigt man sich damit, wie eine Größe einen bestimmten vorgegebenen Wert erreichen und halten kann. Bei einer Regelung
finden Kontrollmechanismen
Anwendung, um Wertabweichungen festzustellen und auszugleichen.\\

Im Folgenden werden wir Techniken aus diesen Teilgebieten betrachten und diese auf ihre Tauglichkeit bezüglich der Lösung unseres beschriebenen Problems untersuchen.
Nicht alle der vorgestellten Techniken sind ohne weiteres auf unsere Problemstellung anwendbar, und wir werden eine Lösung entwickeln, die auf die konkrete
Problemstellung unter Berücksichtigung der gegebenen Umstände zurecht geschnitten ist.

\subsubsection{Staukontrolle bei TCP}
\label{css:tcp}
TCP (Transmission Control Protocol) ist ein verbindungsorientiertes Über\-tra\-gungs\-pro\-to\-koll und kontrolliert die Datenübertragung zwischen Sender und
Empfänger der Endknoten. Dabei wird gewährleistet, dass jedes der einzelnen Datenpakete (die einen Datenstrom formen) den Empfänger erreicht
und die Ordnung der Pakete
innerhalb des Datenstroms bestehen bleibt. Bei Datenstau handelt es sich um Verlust von Datenpaketen. Falls es zu Datenstau kommt, so tritt dieser immer an
Verbindungsknoten (einschließlich des Empfangsknotens) auf und kann durch verschiedene Faktoren auf dem Weg zwischen Sender und Empfänger hervorgerufen werden:
\begin{description}
  \item [Bandbreiten:]
    Unterschiedliche Bandbreiten auf dem Weg zwischen Sender und Empfänger beeinflussen die Übertragungsgeschwindigkeit einer Verbindung
    nachteilig in der
    Form, dass die ``langsamste'' Leitung (also die mit der geringsten Bandbreite) die
    Gesamt-Übertragungsgeschwindigkeit vorgibt. Trifft eine schnelle Leitung auf eine langsame Leitung, so können die an der langsamen Leitung ankommenden
    Pakete nicht schnell genug weiter geleitet werden. An diesem Knoten kommt es zum Pufferüberlauf, überschüssige Datenpakete gehen verloren.
  \item [Anzahl der Verbindungen:]
    An einem Knotenpunkt können mehrere Verbindungen zusammen kommen, die den Gesamt-Datenfluss an diesem Punkt erhöhen. Auch hier kann es zum Pufferüberlauf
    kommen, so dass überschüssige Datenpakete verloren gehen.
\end{description}
Damit jedes ausgesandte Paket den Empfänger erreicht, werden in TCP Bestätigungs-Nachrichten (Acknowledgements, im Folgenden kurz $acks$ genannt) versandt.
Erhält der Sender für ein gesendetes TCP-Datenpaket kein $ack$, so wird er das Datenpaket erneut senden. Ein wichtiger Bestandteil eines Datenpaketes ist
die Sequenznummer \cite{RFC2581}. Anhand der Sequenznummer kann ein $ack$ eindeutig einem versendeten Datenpaket zugeordnet werden. Innerhalb des $acks$ vermerkt
der Empfänger ebenfalls, welches Datenpaket er als nächstes erwartet \cite{RFC793}.
Um eine Staukontrolle zu erreichen wurden einige Algorithmen in TCP integriert (siehe \cite{jacobson88congestion}, wir halten uns dabei an die englischen
Bezeichnungen):
\begin{itemize}
  \item slow-start
  \item round-trip-time variance estimation
  \item exponential retransmit timer backoff
  \item more aggressive receiver ack policy
  \item dynamic window sizing on congestion
  \item Karn's clamped retransmit backoff
  \item fast retransmit
\end{itemize}

Dabei soll erreicht werden, dass die maximal mögliche Bandbreite (begrenzt durch die minimale Bandbreite (``bottleneck'') auf dem Verbindungsweg, s. o.) voll
ausgenutzt wird, ohne
dass Pakete verloren gehen; es darf also kein Paket in das Netzwerk eingespeist werden, bevor ein altes Paket entfernt wurde (die Verbindung befindet sich dann im
``Equilibrium'', der Paketfluss ist ``conservative'' \cite{jacobson88congestion}). Im Folgenden wollen wir die wichtigsten der oben genannten Algorithmen
vorstellen. Eine genaue Herleitung und Analyse der Algorithmen geht jedoch über den Rahmen dieser Arbeit hinaus.
Wir verweisen auf die entsprechenden Quellen in den Literaturangaben.

\paragraph{more aggressive receiver ack policy:}
\footnote{Hier ist in \cite{jacobson88congestion} nicht eindeutig feststellbar,  worauf sich van Jacobson genau bezieht, da er diese Bezeichnung im weiteren Text
nicht mehr verwendet. Es erschien sinnvoll, die folgende im o. g. Text zu findende Erklärung diesem Thema zuzuordnen.}TCP
ist ``self-clocking'': da $acks$ erst nach Erhalt der entsprechenden Datenpakete versendet werden können, bestimmt die Rate der ankommenden $acks$ die
Rate, mit der weitere Datenpakete ausgesendet werden sollen. Die Senderate passt sich somit automatisch der Bandbreite an.

\paragraph{slow-start:}
Durch das ``self-clocking'' tritt nur beim Start des Datentransfers ein Problem auf, da
hier zunächst eine feste Rate gewählt werden muss. Diese wird zu Beginn relativ niedrig gewählt, bzw. ein Staufenster ``congestion window'' ($cngw$) 
bestimmt die Anzahl der Pakete pro Sendevorgang. Bei Start des Transfers oder nach Paketverlust wird die Größe des Staufenster auf 1 gesetzt.
Für jedes $ack$ wird das Staufenster um den Betrag 1 erhöht. Begrenzt wird dessen Größe durch das ``advertised receiver window'',
welches vom Empfänger festgelegt wird und angibt, wieviele Bytes maximal als nächstes übersendet werden sollen. Die Zunahme der Größe $w$ des
Staufensters geschieht in der Zeit
$rtt*log_2w$, wobei $rtt$ die ``round-trip-time'' des letzten versendeten Datenpaketes ist (Zeit zwischen Versenden eines Datenpaketes und Erhalt des
entsprechenden $acks$). Siehe dazu \cite{jacobson88congestion}, \cite{RFC2581}. 

\paragraph{round-trip-time variance estimation:}
\label{cssp:tcp_rtt}
$Acks$ können die Geschwindigkeit des Datenflusses steuern, doch was geschieht, wenn $acks$ aufgrund verloren gegangener Pakete ausbleiben? Müssen sich
beispielsweise bei voll ausgenutzter Bandbreite plötzlich zwei Datenströme dieselbe Leitung teilen, kommt es bei gleichbleibender Datentransferrate mit Sicherheit zu
Paketverlusten und somit zu
ausbleibenden $acks$. Der Sender muss einen Timer unterhalten, bei dessen Ablauf das zuletzt gesendete Datenpaket erneut versendet wird (im Folgenden als
Retransmission bezeichnet). Paketverlust kann auch
durch Beschädigung der Daten während der Übermittlung auftreten. Nach van Jacobson \cite{jacobson88congestion} Liegt die Wahrscheinlichkeit dafür aber weit
unter 1\%. Daher lassen Timeouts bei gut eingestellten Timern mit sicherer Gewissheit auf Paketverluste schließen \footnote{Zur Problematik
bei Timern siehe \ref{css:timer}}. Diese Timeouts werden pro Verbindung dynamisch berechnet; im Folgenden bezeichnet $rto$ das ``retransmission timeout''-Intervall,
also die Zeitdifferenz bis zum nächsten Aussenden eines Datenpaketes. Entsprechend der TCP-Spezifikation
berechnet sich (siehe \cite{18216}):
\[rto=min(UBound, max(LBound, \beta * srtt))\]
$\beta$ ist dabei ein empirisch ermittelter Varianz-Faktor, $UBound$ und $LBound$ sind untere und
obere Schranke für den $rto$. $srtt$ ist die ``smoothed roundtrip time'' und wird wie folgt ermittelt:
\[srtt= \alpha * srtt+ (1 - \alpha) * rtt\] 
$\alpha$ ist ein ebenfalls empirisch ermittelter Glättungsfaktor (``smoothing factor''). Empfohlene Werte sind für $\alpha:$ $0.8 \sim 0.9$ und für $\beta:$
$1.3 \sim 2$ \cite{18216}.\\
Laut van Jacobson \cite{jacobson88congestion} liegt hierin folgende Problematik: $\beta$ kann sich höchstens an eine bis zu 30\% gesteigerte Last anpassen. Aber die
Varianz des Wertes $rtt$ steigert sich rapide mit ansteigender Last. Bei
Laststeigerung über die 30\%-Marke hinaus kommt es zu verspäteten $acks$. Der jeweilige abgelaufene Timer bewirkt eine Retransmission des entsprechenden
Datenpaketes, was zu unnötiger Mehrarbeit des Netzwerkes und zu Bandbreitenverschwendung führt. Daher wird $\beta$ ebenfalls dynamisch berechnet.
Eine Berechnungsmethode findet sich in \cite{jacobson88congestion}.

\paragraph{exponential retransmit timer backoff:}
Um den Datenstau durch mehrfach ausgesandte Pakete nicht noch zu vermehren, muss sich der $rto$ stetig vergrößern.
Van Jacobson \cite{jacobson88congestion} stellt heraus, dass nur exponentielles Wachstum des $rto$ Erfolg verspricht.
Daher wird nach jedem erneuten Aussenden eines nicht bestätigten Datenpaketes der $rto$ verdoppelt.

\paragraph{dynamic window sizing on congestion:}
Ein Vergrößern des $rto$ verhindert nur einen zusätzlichen Datenstau durch erneut ausgesandte Datenpakete. Damit auch die im Anschluss daran neu
ausgesandten Pakete nicht wieder zum Anstieg des Datenstaus führen, wird ebenfalls die Größe der Staufenster $cwnd$ halbiert (exponentielle Abnahme).
Ausbleibende oder verzögerte $acks$ geben nur Auskunft über auftretenden Datenstau. Sie können nicht anzeigen, ob die volle Bandbreite einer Verbindung auch wirklich
ausgenutzt wird. Daher sollte die Größe der Staufenster nach einem bestimmten Schema angehoben werden. Die Anpassung von $cwnd$ geschieht nach folgendem Prinzip:
\begin{itemize}
  \item Nach jedem Timeout wird $cwnd$ halbiert.
  \item Nach jedem $ack$ für neue Daten wird $cwnd$ um $1/cwnd$ erhöht.
  \item Beim Senden wird das Minimum and Daten von $cwnd$ und dem ``receivers advertised window'' gesendet.
\end{itemize}

Dieser Algorithmus trägt zur Stauvermeidung (``congestion avoidance'') bei und besteht parallel zum ``slow-start''-Algorithmus. Van Jacobson gibt in
\cite{jacobson88congestion} ein Auswahlkriterium an, nachdem zustandsabhängig zwischen beiden Algorithmen ausgewählt wird.

\paragraph{Karn's clamped retransmit backoff:}
\label{csp:karns_algorithmus}
Sequenznummern ermöglichen die Zuordnung eines $acks$ zu dem entsprechenden Datenpaket. Kommt es aufgrund von Timeouts zu Retransmissionen
desselben Datenpaketes, so tritt ein Problem auf, welches Karn und Partridge in \cite{Karn1991} als ``retransmission ambiguity'' bezeichnen:
es kann nicht festgestellt werden, auf welche Aussendung desselben Datenpaketes sich das $ack$ bezieht. Damit ist nicht klar, anhand welches Paketes
sich der $rtt$ bestimmen soll, er wird in jedem Falle nicht verlässlich sein. Verschiedene Protokollimplementationen behandeln dieses Problem
auf unterschiedliche Weise: teils wird die am längsten zurückliegende Aussendung als Grundlage zur Berechnung herangezogen, teils die am kürzesten zurückliegende
Aussendung.\\

Wird die am längsten zurückliegende Aussendung  gewählt, so können der $rtt$, damit der $srtt$ und letztlich der $rto$ unverhältnismäßig in die Höhe schießen.
In vielen Fällen ist die nachteilige Wirkung nicht besonders groß, da aufgrund des Datenstaus eine Drosselung der Datentransferrate erwünscht ist.
Kommt es aufgrund anderer Ursachen zu Paketverlusten (z. B. bei verlustreichen Leitungen durch Störsignale), so tritt das Gegenteil des gewünschten Verhaltens
ein: der $srtt$ sinkt auf ein sehr niedriges Niveau, obwohl sich in diesem Falle die Datentransferrate erhöhen sollte.\\

Wird die am kürzesten zurückliegende Aussendung herangezogen, so ist die Wahrscheinlichkeit laut Karn sehr groß, dass die Zeitfolge zwischen dieser Sendung und dem
ankommenden $ack$ sehr kurz ist, obwohl sich das $ack$ auf eine weiter zurückliegende Sendung bezieht. Dies führt zu einer drastischen Reduzierung des $srtt$,
was überflüssige Retransmissionen und damit eine zusätzliche Verschwendung der Bandbreite zur Folge hat (\cite{Karn1991},\cite{Jain1986}). Andere Implementationen
lassen die $rtt$ bei Retransmissionen außer acht. Dies geht gut, solange der $rto$ nicht schneller ansteigt, als der Algorithmus sich adaptieren kann. Ist $\beta$
gut gewählt, so ist die Möglichkeit dafür sehr gering. Tritt dieser Fall dennoch ein, so kommt es (wie im letztgenannten Fall) zu überflüssigen Retransmissionen.\\

Um diesem Problem zu begegnen, schlägt Karn folgenden Algorithmus vor \cite{Karn1991}:\\
Grundsätzlich wird der $rto$ nach einem Timeout vergrößert (``back-off'').
Erreicht ein $ack$ den Sender nach einer Retransmission eines Datenpaketes, so wird keine Neuberechnung des $rtt$ und $srtt$ vorgenommen. Dafür wird der neu
ermittelte (``backed-off'') $rto$ als Grundlage für die nächste Retransmission bzw. für die Aussendung des nächsten Datenpaketes herangezogen. Nur wenn ein $ack$
den Sender ohne vorausgehende Retransmission erreicht, wird der $rto$ mit Hilfe des nun neu berechneten $srtt$ ermittelt.\\
Die Wahl des neuen $rto$ im Falle einer Retransmission muss laut Karn so erfolgen, dass der $rto$ größer ist als die tatsächliche Roundtrip-Time. Typischerweise
geschieht die Steigerung des $rto$ exponentiell (entsprechend des ``exponential retransmit timer backoff'', s. o.).

\paragraph{fast retransmit:}
Erreichen den Sender vier identische $acks$ in Folge, so wird der Sender das vom Empfänger erwartete Datenpaket sofort aussenden, ohne auf das
Ablaufen des Retransmissionstimers zu warten. ``Slow-start'' wird so lange ausgesetzt, bis ein anderes, nicht zu den vorherigen identisches $ack$ den Sender
erreicht  (\cite{RFC2581}). Die identischen $acks$ lassen sowohl darauf schließen, dass ein Datenpaket verloren gegangen ist, als auch, dass andere Datenpakete den
Empfänger höchstwahrscheinlich erreichen, da die identischen $acks$ sonst ausgeblieben wären. Die den identischen $acks$ zugrundeliegenden Datenpakete beeinflussen
das Datenaufkommen nicht mehr, da diese schon die Empfänger-Queue erreicht haben. Daher geht man davon aus, dass das erneute, schnelle Senden des fehlenden
Datenpaketes das Netz nicht wesentlich im Negativen beeinflusst. ``Fast retransmit'' sollte, muss aber nicht von einer konkreten TCP-Implementation unterstützt
werden.\\

Zusätzliche Erweiterungen zum TCP in Hinsicht auf hohe Performanz finden sich in \cite{jacobson93tcp}.

\paragraph{Bezug zur Zielsetzung:}
Wie zu Beginn des Abschnittes gesagt, geht es darum, die Auslastung der Server-Queue stabil zu halten, bzw. dafür zu sorgen,
dass die Ungleichung $0\leq\rho<1$ erfüllt
ist.\\

Zeigen wir zunächst die Parallelen zwischen unserem Kommunikationsmodell und der Ebene, auf der TCP Anwendung findet: bei unserem Kommunikationsmodell
befinden sich die kommunizierenden Parteien (RSS-Server, Subscriber) ebenfalls an Endknoten. Befindet sich der RSS-Server unter starker Last, so wird seine
Antwort (die Übermittlung des RSS-Feeds) länger auf sich warten lassen, als unter geringerer Last. Die $rtt$ zwischen Anfrage und dem vom RSS-Server übermittelten
Feed (entsprechend einem $ack$) lässt in gewissem Rahmen auf die Auslastung des Servers schließen. Auch in unserem Fall kann die Antwortzeit durch
ein starke Netzbelastung und dadurch verursachte
lange Übertragungszeiten negativ beeinflusst sein. Dies würde eventuell unser Ergebnis verfälschen, da wir nur an der Stärke der Serverlast interessiert sind,
die Netzbelastung spielt für uns keine Rolle. Um Teillösungen zu finden, wollen wir aber zunächst von den Nachrichtenlaufzeiten abstrahieren. Auch in unserem
Falle muss der Subscriber, sollte die Server-Antwort ausfallen, seine Anfrage erneut senden. Dafür sollte er ebenfalls einen Timer mit laufen lassen. Wie bei
TCP sollte sich der $rto$ stetig vergrößern, um die Serverbelastung nicht noch zu steigern. Erreicht die Server-Antwort den Subscriber
lediglich verspätet, nach dem die Anfrage bereits wiederholt gesendet wurde, kommt es hier in jedem Falle zum Problem der ``retransmission ambiguity'': der
Subscriber kann nicht zuordnen, auf welche Anfrage sich die Antwort bezieht,
da unser Ansatz keine Sequenznummern zulässt. In diesem Sinne gibt es bei unserem Ansatz keinen Unterschied zwischen regulären Anfragen und Retransmissionen von
Anfragen, da sich der Informationsgehalt der Anfragen grundsätzlich nicht unterscheidet. Ob wir an dieser Stelle Karns Lösung favorisieren oder eine andere Lösung
wählen, werden wir im Abschnitt \ref{css:staukontrolle_pubsubrss} erörtern.

\subsubsection{Anwendung eines Regelkreises}
Die Aufgabe einer Regelung besteht darin, bestimmte Größen (Temperatur, Spannung, etc.) auf einen
vorgeschriebenen Wert zu bringen und diesen entgegen allen Störeinflüssen konstant zu halten (\cite{Bernstein1998}). Bei der Regelung unterscheidet man zwischen
verschiedenen Größen, die zusammen einen Regelkreis bilden: 
\begin{description}
  \item [Regelgröße $x$] oder auch der Istwert: Größe, welche konstant gehalten werden soll und zu diesem Zweck erfasst wird
  \item [Führungsgröße $w$] oder auch Sollwert: vorgegebener Wert, auf den die Regelgröße eingestellt werden soll
  \item [Störgröße $z:$] Größe, die die Regelgröße in unerwünschter Weise beeinflusst
  \item [Regeldifferenz $x_d:$] Differenz zwischen Führungs- und Regelgröße $x_d=w-x$
  \item [Stellgröße $y:$] Größe, durch welche die Regelgröße in erwünschter Weise beeinflusst wird
\end{description}

\begin{picturehere}{1}{4}{Regelkreis}{Abb:Regelkreis}
 \includegraphics[bb=180 0 682 141,scale=0.75]{Regelkreis}
\end{picturehere}

%\includegraphics[scale=0.75]{Regelkreis.pstex}

Bild \ref{Abb:Regelkreis} zeigt das vereinfachte Schema eines Regelkreises. Die Regelung basiert auf Rückkopplung. Bewirkt der Einfluss der Störgröße eine Abweichung
der Regelgröße von der Führungsgröße, so ergibt die Regeldifferenz über einen Regler eine Stellgröße, die entgegengesetzt zur Störgröße auf die Regelgröße einwirkt.
Ziel dabei ist es, die Regeldifferenz auf Null zu bringen.

Die Wahl eines geeigneten Reglers hängt stark von der Regelstrecke ab. Die Regelstrecke bezeichnet die zu regelnde Anlage oder den zu regelnden Prozeß. Wichtig zu
wissen ist, wie die Regelstrecke auf Änderung der Einflussgrößen reagiert. Nach \cite{Bernstein1998} kann man die Regelstrecken grob durch folgende Merkmale 
unterscheiden:
\begin{itemize}
  \item Regelstrecken mit und ohne Ausgleich
  \item Regelstrecken mit und ohne Totzeiten bzw. Zeitglieder
  \item lineare oder nichtlineare Regelstrecken
\end{itemize}

Bei Regelstrecken mit Ausgleich erreicht die Ausgangs- bzw. Regelgröße nach einer gewissen Zeit einen stabilen Zustand (Bsp. Raumtemperatur). Existiert kein
stabiler Zustand (Regelstrecke ohne Ausgleich), so ändert sich bei konstanter Eingangs- bzw. Stellgröße die Regelgröße mit
konstanter Geschwindigkeit oder Beschleunigung (Bsp. Füllen eines Wasserbehälters). Totzeit bezeichnet eine Zeitverzögerung, bis sich die Änderung der Stellgröße
auf die Regelgröße bemerkbar macht. Bei linearen Regelstrecken folgt die Regelgröße der Stellgröße proportional.

Meist liegt eine Kombination dieser Eigenschaften vor. Um die Stellgröße entsprechend der Regeldifferenz anzupassen, wird ein Regler benötigt.

\paragraph{PID-Regler:}
Ein PID-Regler ist ein allgemeiner Reglertyp, der häufig für Regelungen Verwendung findet. Er ist eine Kombination aus einem P-, einem I- und einem D-Regler.
Ein P-Regler sorgt dafür, dass (im stationären Zustand) ein dem Eingangssignal proportionales Ausgangssignal geliefert wird (unter Zuhilfenahme eines
Verstärkungsfaktors). Ein I-Regler summiert die Regeldifferenz über einen gewissen Zeitraum und führt damit eine Integration aus. Je länger eine Regeldifferenz
besteht, desto größer wird die Stellgröße. Ein D-Regler reagiert nur auf die Änderungsgeschwindigkeit der Regeldifferenz. Er liefert einen entsprechend starken,
kurzen positiven Impuls (ein reiner D-Regler hat in der Praxis keine Bedeutung).

Die allgemeine mathematische Gleichung für einen PID-Regler lautet wie folgt (siehe \cite{WBuettner1991}):
\[u(t)=K_R\left[\quad e(t) \quad + \quad \frac{1}{T_I}\int\limits_{0}^{t}e(\tau)d\tau \quad + \quad T_D\frac{de(t)}{dt} \quad \right]\]

Die einzelnen Größen sind:
\begin{description}
  \item [$u(t)$] Stellgröße
  \item [$e(t)$] Regeldifferenz
  \item [$K_R$] Verstärkungsfaktor
  \item [$T_I$] Integrationskonstante
  \item [$T_D$] Differentiationskonstante
\end{description}

Es werden nicht für alle Regelungen alle Anteile benötigt. Durch weglassen der entsprechenden Anteile erhält man die Regler P, PI bzw. PD. Reine P-Regler finden
nur Verwendung bei Regelstrecken linearen Verlaufs. Doch selbst hier zeigt sich, dass bei Regelabweichungen, die durch eine Störgröße hervorgerufen werden, die
Störgröße lediglich in ihrer Wirksamkeit gemindert werden kann. Eine vollständige Beseitigung tritt nicht ein, da die Regelabweichung selbst notwendig ist, um eine
Verstellung des Stellgliedes vorzunehmen (\cite{Bernstein1998}). Mit einem I-Regler kann man die Regelabweichung sehr genau unterbinden, jedoch arbeitet dieser
relativ langsam und neigt zu Schwingungen. Die Vorteile beider Reglertypen vereint der PI-Regler. Reine D-Regler finden in der Praxis keine Verwendung, da sie bei
stabiler Regelgröße nicht in den Regelvorgang eingreifen können. Die Kombination mit einem P-Regler (also ein PD-Regler) bewirkt ein schnelleres Anspringen der
Regelung bei plötzlicher Regelabweichung im Vergleich zu einem reinen P-Regler.\\

\paragraph{Bezug zur Zielsetzung:}
Wir können die Erfüllung der Ungleichung $0\leq\rho<1$ durch einen Regelkreis beschreiben. Die zu regelnde Größe ist dabei $\rho$. Die Stellgröße
ist $cpp$. Aus Sicht eines Klienten
sind die $cpp$s der übrigen Klienten eine Störgröße, da ihre Veränderung die Auslastung des Servers beeinflusst. Bei der Regelstrecke handelt es
sich im allgemeinen um einen nicht-linearen Typ mit Ausgleich und Totzeit. Als Regler sollten wir daher einen PI-Regler verwenden. Eine differentiale Eigenschaft
wollen wir zunächst außer acht lassen, da diese nur zur Feinabstimmung beiträgt.\\

Um $\rho$ messen zu können, muss der Regler einen direkten Zugriff auf die Werte $\lambda$ und $\bar x$ (s.o.) erhalten können.
Dies ist aber im allgemeinen, bzw. bei unserem
favorisierten Ansatz nicht möglich, da nur der Server diese Werte ermitteln kann und diese entsprechend des Konzeptes nicht an die Klienten übermittelt.
Ein Klient kann somit nur aufgrund anderer Indizien auf diese Werte rückschließen.
Das einzige Indiz ist das Antwortverhalten bzw. die Antwortzeit des Servers auf eine Anfrage des Klienten. Abstrahieren wir von den Nachrichtenlaufzeiten,
so lässt eine lange Antwortzeit des Servers auf einen gewissen Überlastungsgrad schließen. Mit Hilfe der $rtt$ können wir somit die $cpp$ bestimmen, also
$cpp=f*rtt$, wobei $f$ ein beliebiger Faktor ist (proportionaler
Anteil des Reglers). Eine konstante Abtastrate wäre wünschenswert, damit ein Regler zu jedem
Zeitpunkt die gleiche Reaktionszeit zeigen kann. Falls wir nur mit den regulären Anfragen nach RSS-Feeds zur Bestimmung der Server-Antwort arbeiten,
bewirkt eine Drosselung des $cpp$ ebenfalls eine Drosselung der Abtastrate.
Man könnte die Reaktionszeit des Servers anders ermitteln, z. B. durch konstantes Anpingen (z. B. mit Hilfe des Kommandos ``ping'').
Dies hätte jedoch u. a. zur Folge, dass dadurch bei einer großen Anzahl Klienten im Overlay-Netzwerk ebenfalls
eine Server-Überlastung erreicht werden könnte. Die Beobachtung der zu regelnden Größe würde diese also gleichzeitig beeinflussen. Außerdem erreicht ein Ping
nicht die Anwendungsschicht des Servers, eine Überlastung auf dieser Ebene bleibt eventuell unbemerkt. Des Weiteren kann es vorkommen,
dass eine Anfrage eines Klienten bei voller Queue vom Server verworfen wird. Eine Server-seitige Antwort wird in diesem Falle ausbleiben. Nach einem gewissen
Timeout muss also der Klient seine Anfrage erneut stellen. Ist dieses Timeout konstant und relativ klein, so kann dies ebenfalls zu einer Mehrbelastung des Servers
führen. Hierbei kommt das für den Regler erforderliche Ereignis (Server-Antwort) gar nicht zustande, somit kann eine Regelung über den Regler gar nicht in der
gewünschten Weise stattfinden. Das Indiz für eine gesteigerte Server-Belastung ist hier also eine Negativ-Nachricht: das Ausbleiben der Server-Antwort. Um die
Mehrbelastung des Servers in diesem Fall einzudämmen, können wir die Timeouts und somit die $ccp$ je nach Zeitdauer vergrößern (integrativer Anteil,
vgl. Abschnitt \ref{css:tcp} TCP).\\

Es zeigt sich, dass das Konzept des PID-Reglers nur modifiziert anwendbar ist auf unsere Problemstellung.
Wie schon angedeutet, werden wir die Grundideen eines PID-Reglers in unserer hergeleiteten Methode wiederfinden.

\subsubsection{Grundsätzliches zu Timern}
\label{css:timer}
\todo{folgt}

\subsubsection{Staukontrolle bei Pub/Sub-RSS}
\label{css:staukontrolle_pubsubrss}
Wollen wir kurz zusammenfassen, welche primären Ziele und damit verbundenen sekundären Ziele wir verfolgen: grundsätzlich geht es um die Bestimmung des Wertes
$ttr$ eines Subscribers (siehe Abschnitt \ref{cs:der_grundlegende_algorithmus}).
Zur Erinnerung: $ttr$ bezeichnet ``Time-To-Refresh'', also den konkreten Zeitpunkt, zu dem die nächste Anfrage an den jeweiligen RSS-Server
gestellt werden soll. Um $ttr$ zu bestimmen benötigen wir $\Delta ttr$. Ein wichtiger Parameter zur Bestimmung von $\Delta ttr$ ist der $cpp$. Um einer
längerfristigen
Überlastung des RSS-Servers entgegenzuwirken, muss der $cpp$ eines Subscribers entsprechend der Serverbelastung angepasst werden.
Wir müssen also ein Maß für die Serverbelastung bestimmen, was auch bei uns die ``Roundtrip-Time'' sein soll, also die Zeit, die zwischen Aussendung
einer Anfrage und dem Erhalt des entsprechenden Feeds vergeht. Soll auch im Folgenden diese durch den Wert $rtt$ bezeichnet sein, den es gilt
zu bestimmen. Mit Hilfe von $rtt$ können wir dann $rto$ und $cpp$ ermitteln.\\

Der konzeptionelle Unterschied zwischen $rto$ und $cpp$ ist folgender: während der $cpp$ zur Berechnung des $\Delta ttr$ bei erfolgreicher Anfrage (also nach Erhalt
eine RSS-Feeds) dient, dient der $rto$ zur Berechnung des $\Delta ttr$ bei nicht erfolgreicher Anfrage, also nach Ablauf des ``Retransmission-Timers'' ohne
Erhalt eines
RSS-Feeds. Ob wir diese Werte separat berechnen, oder ob wir einen funktionalen Zusammenhang zwischen diesen Werten herstellen, werden wir im Folgenden erörtern.

Bei TCP gibt es ebenfalls eine funktionale Unterscheidung zwischen $srtt$ und $rto$, besonders in Zusammenhang mit Karn's Algorithmus
(siehe Abschnitt im Kapitel \ref{csp:karns_algorithmus}),
wobei der $cpp$ hier für den $srtt$ bei TCP steht. Im Unterschied zu TCP reicht bei uns der $cpp$ als Wert für ein Timeout für die nächste Anfrage jedoch nicht aus,
da es in unserem Falle
nicht um einen Datenstrom und somit nicht um die Aussendung des nächsten Datenpaketes geht. In unserem Fall muss die Zeit $\Delta ttr$, deren Bestandteil $cpp$ ist,
bis zum nächsten Aussenden einer Anfrage berechnet werden. Daher werden wir im Folgenden den Begriff $srtt$ nicht verwenden, sondern den bereits
eingeführten Begriff $cpp$, da dieser im Zusammenhang mit \pubsubrss eher angebracht ist.\\

Beim Anpassen des $cpp$ müssen wir berücksichtigen, dass grundsätzlich nicht ein Subscriber alleine für eine Überlastung verantwortlich ist, sondern in den
meisten Fällen eine Menge von Subscribern, die gemeinsam auf den gleichen RSS-Server zugreifen. Eine Senkung des $cpp$ kann also multiplikative Wirkung haben,
da je nach Verfahren diese Maßnahme eventuell jeder beteiligte Subscriber ergreift.\\

Zur Berechnung des $rtt$ müssen wir die RSS-Feeds nach ihrem Ursprung unterscheiden: Feeds, die ein Subscriber von einem Broker erhält, müssen anders behandelt
werden als Feeds, die von einem RSS-Server ausgesandt werden. Für die Berechnung des $rtt$ spielen nur diese Feeds eine Rolle, da nur diese Auskunft über eine
eventuelle Server-Belastung geben können.\\

Ob wir uns bei der Lösung unseres Problems an den Konzepten zur Staukontrolle bei TCP orientieren, oder ob wir uns des Modells eines
Regelkreises bedienen, spielt im Grunde keine Rolle, da die Problematik die gleiche bleibt. Daher wollen wir im Folgenden eine Lösung aufgrund einer
problemorientierten Sichtweise konzipieren und dort Bezüge zu den beiden anderen Konzepten herstellen, wo es angebracht ist.\\

Im Gegensatz zu TCP haben wir es bei den auftretenden Anfragen an den RSS-Server nicht mit einem Datenstrom zu tun, der in eine Folge von
Datenpaketen unterteilt wird, sondern mit unabhängigen Anfragen. Erhält ein Subscriber einen RSS-Feed, welcher als Acknowledgement zu einer Anfrage aufgefasst
werden kann, so spielt es zunächst keine Rolle, auf welche Anfrage dieser sich bezieht. Entscheidend ist, dass dieser Feed der höchstwahrscheinlich aktuellste ist
und die Informationen enthält, die der Subscriber wünscht. Natürlich ist davon auszugehen, dass sich das Overlay-Netzwerk ebenfalls TCP als Übertragungsprotokoll
bedient (denkbar sind jedoch auch Varianten, bei denen z. B. UDP zur Übermittlung eingesetzt wird). Dies spielt sich jedoch auf einer tieferen Schicht ab, von der
wir, wie oben schon gesagt, zunächst noch abstrahieren wollen. Die konkrete Anpassung an TCP findet sich im Kapitel \ref{c:anpassung_an_tcp}.\\
Da wir es nicht mit einem Datenstrom zu tun haben, entfällt zunächst das Problem der Sequenznummern, ein ankommender Feed ist das Datenpaket,
auf das der entsprechende Subscriber wartet. Erhält ein Subscriber
einen Feed, so muss in jedem Fall der $ttr$ für die Aussendung der nächsten Anfrage (im Folgenden als ``Feed-Request'' bezeichnet) berechnet und ein entsprechender
Timer $RQT$ (für ``Request-Timer'') eingerichtet werden, nach dessen Ablauf der Feed-Request versendet wird. Nach Aussendung des Feed-Requests muss nun ein
Timer $RT$ (für ``Retransmission-Timer'') eingerichtet werden, nach dessen Ablauf der Feed-Request erneut ausgesandt wird. Aber da Sequenznummern keine Rolle
spielen, können wir im Grunde definieren: $RT:=RQT$, der $RQT$ wird dann je nach Situation unterschiedlich gesetzt. Mitbestimmend für den $RQT$ ist der $cpp$,
mitbestimmend für den $RT$ der $rto$. Diese beiden Timer laufen nie parallel sondern schließen sich gegenseitig aus. $cpp$ wird ebenfalls je nach Situation
unterschiedlich berechnet. Um eine klarere Differenzierung vorzunehmen, werden wir trotzdem dort zwischen den Begriffen 
$RQT$ und $RT$ unterscheiden, wo es der Deutlichkeit halber angebracht erscheint.\\

Eine untere Schranke für $cpp$ soll $ppp$ bilden. Da jeder Subscriber $ppp$ individuell festlegen kann, ist es nicht notwendig, $cpp$ kleiner als $ppp$ zu wählen.
Das heißt nicht, dass ein Subscriber frühestens nach Ablauf der Zeit $ppp$ einen neuen Feed bekommt: existieren im gleichen Netzwerk andere Subscriber, die einen
niedrigeren $ppp$ eingestellt haben, so kann jener Subscriber davon profitieren, da ihm dann ebenfalls neu auftretende Feeds nach kürzerer Zeit zugestellt werden.
Möchte ein Subscriber sicher gehen, dass ein bestimmter Aktualitätsgrad der Feeds erreicht wird, so muss er eben den $ppp$ entsprechend setzen.\\

Wir wollen ebenfalls eine obere Schranke für $cpp$, den $mpp$ (für maximale Polling-Periode), definieren. Dieser vermeidet, dass bei ungünstigen
Konstellationen der $cpp$ zu groß wird (z. B. wenn zufällig jeder Feed-Request eines Subscribers vom RSS-Server verworfen wird, obwohl der Server nicht stark
überlastet ist). Dieser sollte abhängig vom jeweiligen Overlay-Netzwerk bestimmt werden.\\

\paragraph{Der theoretische Ansatz:}
Der $rtt$ kann nur gemessen werden, wenn ein Subscriber einen RSS-Feed von einem RSS-Server zugesandt bekommt. Grundsätzlich dient der Wert $rtt$ als
Bezugspunkt für $cpp$. Bei jeder Änderung von $rtt$ berechnet sich $cpp$ wie folgt: \[cpp:=min\{mpp,max\{rtt,ppp\}\}\]
Bei Einstieg des Subscribers in das System wird (s. o.) $rtt:=ppp$ gesetzt. Erhält ein Subscriber einen RSS-Feed vom RSS-Server, so wird,
falls der $RT$ bisher noch nicht abgelaufen ist, $rtt$ auf die gemessene Roundtrip-Time gesetzt.
In diesem Falle kann $rtt$ anscheinend eindeutig bestimmt werden (warum nur anscheinend, werden wir später erörtern). Bestimmmend für den $RT$ ist der $rto$,
welcher initial und bei Erhalt eines vom RSS-Server direkt versendeten Feeds auf $rto:=cpp$ gesetzt wird. Bei jeder Aussendung eines Feed-Requests wird
zunächst der $rto$ verdoppelt und $RT$ neu gesetzt. Dies bedeutet exponentielles Wachstum des $rto$. Damit das System skalierbar ist und die Adaption auch bei
großen Netzen noch in angemessener Zeit geschieht, muss die
Anpassung exponentiell erfolgen (siehe ``exponential retransmit timer backoff'' in Abschnitt \ref{css:tcp}).
Bekommt ein Subscriber einen RSS-Feed und ist der $RT$ bereits mindestens einmal abgelaufen, so haben wir hier das gleiche Problem, welches uns schon von
TCP her als ``retransmission ambiguity'' (siehe \ref{csp:karns_algorithmus}, Seite \pageref{csp:karns_algorithmus}) bekannt ist: wir können nicht wissen,
durch welchen Feed-Request der ankommende
Feed ausgelöst wurde. $rtt$ lässt sich in diesem Falle also nicht eindeutig bestimmen. Wie Karn festgestellt hat, ist es sowohl
ungünstig, den zuletzt ausgesandten Feed-Request wie auch den zuerst ausgesandten Feed-Request als Berechnungsgrundlage zu wählen. Wir wollen daher an dieser
Stelle den Mittelwert der möglichen Roundtrip-Times berechnen, um die Differenz zur eigentlichen Roundtrip-Time möglichst gering zu halten.
Hat es $i$ Retransmissionen gegeben, so gilt
$rto=2^i*cpp$. Dann wählen wir \[rtt:=\frac{2^{i-1}*cpp+\Delta t}{i}\] Dabei ist $\Delta t$ die Zeitspanne zwischen der letzten Retransmission und $t_0$,
wobei gilt $0\leq\Delta t\leq 2^i*cpp$.
Der Ansatz, die Berechnungen von $cpp$ und $rto$ zu trennen, ist dem von Karn sehr ähnlich, nur ist die Berechnung eine andere. Hier kann
man auch eine Analogie zur Idee der PI-Reglern herstellen (obwohl es nur Parallelen in den Grundideen gibt): während man den bereits berechneten $cpp$
als proportionalen Anteil in der Berechnung auffassen kann, gibt es eine Parallele zwischen der Anpassung des $rto$ und dem integrativen Anteil beim PI-Regler,
da die Anpassung des $rto$ die zeitliche Dauer der Server-Antwort berücksichtigt.\\

Ein Varianzfaktor wird hierbei nicht hinzugezogen. Berechnungen auf dieser Grundlage
lieferten in der Simulation gute Ergebnisse. Eine Optimierung wäre eventuell möglich, wenn man einen Varianzfaktor entsprechend der $rto$-Berechnung bei
TCP hinzuzieht. Dies soll aber nicht Gegenstand dieser Arbeit sein und soll offen bleiben für weitere Forschungen.
Neuberechnungen von $cpp$ und $rtt$ finden zunächst nur dann statt, wenn ein Subscriber einen RSS-Feed von einem RSS-Server erhält.
Weitere Verbesserungen werden wir in Abschnitt \ref{cs:ausbalancierung_der_polling-perioden} betrachten.\\

\paragraph{Ungenauigkeiten und Probleme:}
Wie oben angedeutet, entspricht der gemessene $rtt$, auch wenn der $RT$ noch nicht abgelaufen ist, nicht immer der tatsächlichen Roundtrip-Time.
Denn denkbar ist folgendes
Szenario: aufgrund abgelaufener Retransmissionstimer hat ein Subscriber einige Feed-Requests mehrfach ausgesandt. Diese sind aber nicht verloren gegangen, sondern
befinden sich in der Queue des RSS-Servers, welcher einer zeitgerechten Antwort nicht nachkommen kann. Der erste vom Server ausgesandte Feed dient als
Berechnungsgrundlage für den $rtt$ des Subscribers, welcher nach kurzer Zeit (nach Ablauf von $RQT$) eine neue (erste) Anfrage stellt. Sendet ihm nun der RSS-Server
einen Feed aufgrund eines noch in der Queue befindlichen Feed-Requests, so interpretiert der Subscriber jenen als Antwort auf seine letzte Anfrage, obwohl er sich
noch auf die vorherige Anfrageserie bezieht. In diesem Falle ist der $rtt$ falsch. Dieses Problem ließe sich nur beheben, wenn die Feeds den Feed-Requests
eindeutig zuordenbar wären (z. B. durch Sequenz- und Retransmissions-Sequenznummern). Da unser Ansatz dies nicht zulässt, müssen wir diese eventuelle Ungenauigkeit
leider in Kauf nehmen.\\

Ein Problem ist denkbar, welches sich auch in der Simulation gezeigt hat: einige wenige Subscriber, welche Anfragen mit einer hohen Frequenz aussenden (also
bei einer sehr niedrigen Polling-Periode) können die übrigen Subscriber ``aussperren''. Die Subscriber, welche eine geringe Polling-Periode berechnet haben, können
diese halten, da ihre Anfragen (bedingt durch deren Menge) eine größere Chance haben, in der Server-Queue zu landen. Somit erhalten sie die Feeds als Antwort auch
mit einer höheren Frequenz vom Server. Dagegen schießen die Polling-Perioden der übrigen Subscriber in die Höhe.
Denn gerade durch den Umstand, dass ihre
Anfragen seltener in der Server-Queue landen, werden sie durch die daraufhin verzögerten (oder ausbleibenden) Antworten ihre Polling-Perioden anheben.
Dieser Rückkopplungseffekt führt dazu, dass sich ihre Polling-Perioden dauerhaft auf hohem Niveau befinden und für diese Subscriber kaum Chancen bestehen,
Feeds vom Server zu erhalten. Natürlich bekommen diese Subscriber ebenfalls die Feeds über das Netzwerk zugesandt. Die Polling-Perioden der verschiedenen Subscriber
sind aber stark auseinander gerissen, sie befinden sich in Dysbalance. Verlassen nun die Subscriber mit einer geringen Polling-Periode das Netz, so steht dieses
zunächst fast still, da die restlichen Subscriber Anfragen erst nach einer großen Zeitdifferenz erneut aussenden. Wie man dieser Dysbalance entgegenwirken kann,
werden wir in Abschnitt \ref{cs:ausbalancierung_der_polling-perioden} darstellen.\\

Ein \label{cssp:ung_u_probl:dysbalance} weiterer eventuell problematischer Punkt ist die Berechnung von $rtt$, falls $RT$ noch nicht abgelaufen ist.
In diesem Fall wird bei unserer Berechnung
der $rtt$ direkt auf die gemessene Roundtrip-Time gesetzt, während bei TCP diese nur zum Teil (unter zusätzlicher Zuhilfenahme des Glättungsfaktors $\alpha$,
siehe Abschnitt \ref{cssp:tcp_rtt}, Seite \pageref{cssp:tcp_rtt}) in die Berechnung eingeht. Man könnte nun berechtigt einwenden, dass diese direkte
Rück\-setzung zu einem starken Schwingungsverhalten der
Server-Belastung und somit der Polling-Perioden im System führen kann. Hier könnte man erwidern, dass einerseits eine schnelle Reaktion des Systems auf eine
verbesserte Server-Reaktionsfähigkeit erwünscht ist und andererseits nicht alle Subscriber gleichzeitig den $rtt$ auf diese Weise ermitteln werden. Von dieser
Wunschvorstellung können wir jedoch nicht ausgehen. Tatsächlich kann es passieren, dass es bei einer plötzlichen Erreichbarkeit des Servers zu einem Ansturm
auf diesen kommt. Wir werden aber
in Zusammenhang mit der vorgestellten Technik in Abschnitt \ref{cs:ausbalancierung_der_polling-perioden} dieses Phänomen eindämmen können. 
